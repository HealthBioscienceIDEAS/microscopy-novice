<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Lesson Title: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="manifest" href="../site.webmanifest">
<link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav IDEAS"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="IDEAS" src="../assets/images/IDEAS-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav IDEAS" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="IDEAS" src="../assets/images/IDEAS-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Lesson Title
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
      <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Lesson Title
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
<input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset>
</form>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Lesson Title
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress IDEAS">
    <div class="progress-bar IDEAS" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="imaging-software.html">1. Imaging Software</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="what-is-an-image.html">2. What is an image?</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="image-display.html">3. Image display</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="multi-dimensional-images.html">4. Multi-dimensional images</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="filetypes-and-metadata.html">5. Filetypes and metadata</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="designing-a-light-microscopy-experiment.html">6. Designing a light microscopy experiment</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-imaging-software"><p>Content from <a href="imaging-software.html">Imaging Software</a></p>
<hr>
<p> Last updated on 2023-12-19 | 
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/imaging-software.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time <i aria-hidden="true" data-feather="clock"></i> 40 minutes </p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right"> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the different software options for viewing microscopy
images?</li>
<li>How can Napari be used to view images?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain the pros and cons of different image visualisation tools
(e.g. ImageJ, Napari and proprietary options)</li>
<li>Use Napari to open images</li>
<li>Navigate the Napari viewer (pan/zoom/swapping between 2D and 3D
views…)</li>
<li>Explain the main parts of the Napari user interface</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="choosing-the-right-tool-for-the-job"><h2 class="section-heading">Choosing the right tool for the job<a class="anchor" aria-label="anchor" href="#choosing-the-right-tool-for-the-job"></a>
</h2>
<hr class="half-width">
<p>Light microscopes can produce a very wide range of image data (we’ll
see some examples in episode X) - for example:</p>
<ul>
<li>2D or 3D</li>
<li>Time series or snapshots</li>
<li>Different channels</li>
<li>Small to large datasets</li>
</ul>
<figure><img src="../fig/images-mosaic.png" style="width:80.0%" alt="A mosaic of screenshots of some of Napari's  included sample data" class="figure mx-auto d-block"></figure><p>With such a wide range of data, there comes a huge variety of
software that can work with these images. Different software may be
specialised to specific types of image data, or to specific research
fields. There is no one ‘right’ software to use - it’s about choosing
the right tool for yourself, your data, and your research question!</p>
<p>Some points to consider when choosing software are:</p>
<ul>
<li><p><strong>What is common in your research field?</strong><br>
Having a good community around the software you work with can be
extremely helpful - so it’s worth considering what is popular in your
department, or in relevant papers in your field.</p></li>
<li><p><strong>Open source or proprietary?</strong><br>
We’ll look at this more in the next section, but it’s important to
consider if the software you are using is freely available, or requires
a one-off payment or a regular subscription fee to use.</p></li>
<li><p><strong>Support for image types?</strong><br>
For example, does it support 3D images, or timeseries?</p></li>
<li><p><strong>Can it be automated/customised/extended?</strong><br>
Can you automate certain steps with your own <em>scripts or
plugins</em>? This is useful to make sure your analysis steps can be
easily shared and reproduced by other researchers. It also enables you
to add extra features to a piece of software, and automate repetitive
steps for large numbers of images.</p></li>
</ul>
<div id="what-are-scripts-and-plugins" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="what-are-scripts-and-plugins" class="callout-inner">
<h3 class="callout-title">What are scripts and plugins?<a class="anchor" aria-label="anchor" href="#what-are-scripts-and-plugins"></a>
</h3>
<div class="callout-content">
<p>Scripts and plugins are ways to automate certain software steps or
add new features.</p>
<div class="section level4">
<h4 id="scripts">Scripts<a class="anchor" aria-label="anchor" href="#scripts"></a>
</h4>
<p>Scripts are lists of commands to be carried out by a piece of
software e.g.  load an image, then threshold it, then measure its size…
They are normally used to automate certain processing steps - for
example, rather than having to load each image individually and click
the same buttons again and again in the user interface, a script could
load each image automatically and run all those steps in one go. Not
only does this save time and reduce manual errors, but it also ensures
your workflow can easily be shared and reproduced by other
researchers.</p>
</div>
<div class="section level4">
<h4 id="plugins">Plugins<a class="anchor" aria-label="anchor" href="#plugins"></a>
</h4>
<p>Plugins, in contrast to scripts, are focused on adding optional new
features to a piece of software (rather than automating use of existing
features). They allow members of the community, outside the main team
that develops the software, to add features they need for a particular
image type or processing task. They’re designed to be re-useable so
other members of the community can easily benefit from these new
features.</p>
</div>
</div>
</div>
</div>
<p>A good place to look for advice on software is the <a href="https://forum.image.sc/" class="external-link">image.sc forum</a> - a popular forum for
image analysis (mostly related to biological or medical images).</p>
<div id="using-the-image.sc-forum" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="using-the-image.sc-forum" class="callout-inner">
<h3 class="callout-title">Using the image.sc forum<a class="anchor" aria-label="anchor" href="#using-the-image.sc-forum"></a>
</h3>
<div class="callout-content">
<p>Go to the <a href="https://forum.image.sc/" class="external-link">image.sc forum</a> and
take a look at the pinned post called ‘Welcome to the Image.sc
Forum!’</p>
<ul>
<li><p>Search for posts in the category ‘Announcements’ tagged with
‘napari’</p></li>
<li><p>Search for posts in the category ‘Image Analysis’ tagged with
‘napari’</p></li>
<li><p>Click on some posts to see how questions and replies are laid
out</p></li>
</ul>
</div>
</div>
</div>
</section><section id="open-source-vs-proprietary"><h2 class="section-heading">Open source vs proprietary<a class="anchor" aria-label="anchor" href="#open-source-vs-proprietary"></a>
</h2>
<hr class="half-width">
<p>A key factor to consider when choosing software is whether it is open
source or proprietary:</p>
<ul>
<li><p><strong>Open source</strong>: Software that is made freely
available to use and modify.</p></li>
<li><p><strong>Proprietary</strong>: Software that is owned by a company
and usually requires either a one-off fee or subscription to
use.</p></li>
</ul>
<p>Both can be extremely useful, and it is very likely that you will use
a mix of both to view and analyse your images. For example, proprietary
software is often provided by the manufacturer when a microscope is
purchased. You will likely use this during acquisition of your images
and for some processing steps after.</p>
<p>There are pros and cons to both, and it’s worth considering the
following:</p>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>
  Pros and cons of open-source / proprietary
  </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<p><strong>Cost</strong><br>
One of the biggest advantages of open source software is that it is
free. This means it is always available, even if you move to a different
institution that may not have paid for other proprietary software.</p>
<p><strong>Development funding/team</strong><br>
Proprietary software is usually maintained by a large team of developers
that are funded full time. This may mean it is more stable and
thoroughly tested/validated than some open-source software. Some
open-source projects will be maintained by large teams with very
thorough testing, while others will only have a single developer
part-time.</p>
<p><strong>Flexibility/extension</strong><br>
Open-source software tends to be easier to extend with new features, and
more flexible to accommodate a wide variety of workflows. Although, many
pieces of proprietary software have a plugin system or scripting to
allow automation.</p>
<p><strong>Open file formats and workflows</strong><br>
Open-source software uses open file formats and workflows, so anyone can
see the details of how the analysis is done. Proprietary software tends
to keep the implementation details hidden and use file formats that
can’t be opened easily in other software.</p>
</div>
</div>
</div>
</div>
<p>As always, the right software to use will depend on your preference,
your data and your research question. This being said, we will only use
open-source software in this course, and we encourage using open-source
software where possible.</p>
</section><section id="fijiimagej-and-napari"><h2 class="section-heading">Fiji/ImageJ and Napari<a class="anchor" aria-label="anchor" href="#fijiimagej-and-napari"></a>
</h2>
<hr class="half-width">
<p>While there are many pieces of software to choose from, two of the
most popular open-source options are <a href="https://imagej.net/software/fiji/" class="external-link">Fiji/ImageJ</a> and <a href="https://napari.org/" class="external-link">Napari</a>. They are both:</p>
<ul>
<li>Freely available</li>
<li>‘General’ imaging software i.e. applicable to many different
research fields</li>
<li>Supporting a wide range of image types</li>
<li>Customisable with scripts + plugins</li>
</ul>
<p>Both are great options for working with a wide variety of images - so
why choose one over the other? Some of the main differences are listed
below if you are interested:</p>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">
  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>
  Differences between Fiji/ImageJ and Napari
  </h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler2" aria-labelledby="headingSpoiler2">
<div class="accordion-body">
<p><strong>Python vs Java</strong><br>
A big advantage of Napari is that it is made with the Python programming
language (vs Fiji/ImageJ which is made with Java). In general, this
makes it easier to extend with scripts and plugins as Python tends to be
more widely used in the research community. It also means Napari can
easily integrate with other python tools e.g. Python’s popular machine
learning libraries.</p>
<p><strong>Maturity</strong><br>
Fiji/ImageJ has been actively developed <a href="https://imagej.net/software/imagej/" class="external-link">for many years now (&gt;20
years)</a>, while Napari is a more recent development <a href="https://napari.org/stable/community/team.html#project-history" class="external-link">starting
around 2018</a>. This difference in age comes with pros and cons - in
general, it means that the core features and layout of Fiji/ImageJ are
very well established, and less likely to change than Napari. With
Napari, you will likely have to adjust your image processing workflow
with new versions, or update any scripts/plugins more often. Equally, as
Napari is new and rapidly growing in popularity, it is quickly gaining
new features and attracting a wide range of new plugin developers.</p>
<p><strong>Built-in tools</strong><br>
Fiji/ImageJ comes with many image processing tools built-in by default -
e.g.  making image histograms, thresholding and gaussian blur (we will
look at these terms in a later episode). Napari, in contrast, is more
minimal by default - mostly focusing on image display. It requires
installation of additional plugins to add many of these features.</p>
<p><strong>Specific plugins</strong><br>
There are excellent plugins available for Fiji/ImageJ and Napari that
focus on specific types of image data or processing steps. The
availability of a specific plugin will often be a deciding factor on
whether to use Fiji/ImageJ or Napari for your project.</p>
<p><strong>Ease of installation and user interface</strong><br>
As Fiji/ImageJ has been in development for longer, it tends to be
simpler to install than Napari (especially for those with no prior
Python experience). In addition, as it has more built-in image
processing tools, it tends to be simpler to use fully from its user
interface. Napari meanwhile is often strongest when you combine it with
some Python scripting (although this isn’t required for many
workflows!)</p>
</div>
</div>
</div>
</div>
<p>For this lesson, we will use Napari as our software of choice. It’s
worth bearing in mind though that Fiji/ImageJ can be a useful
alternative - and many workflows will actually use both Fiji/ImageJ and
Napari together! Again, it’s about choosing the right tool for your data
and research question.</p>
</section><section id="opening-napari"><h2 class="section-heading">Opening Napari<a class="anchor" aria-label="anchor" href="#opening-napari"></a>
</h2>
<hr class="half-width">
<p>Let’s get started by opening a new Napari window - you should have
already followed the <a href="index.html#setup">installation instructions</a>.
Note this can take a while the first time, so give it a few minutes!</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate napari-env</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">napari</span></span></code></pre>
</div>
<figure><img src="../fig/blank-napari-ui.png" alt="A screenshot of the default Napari user  interface" class="figure mx-auto d-block"></figure></section><section id="opening-images"><h2 class="section-heading">Opening images<a class="anchor" aria-label="anchor" href="#opening-images"></a>
</h2>
<hr class="half-width">
<p>Napari comes with some example images - let’s open one now. Go to the
top menu-bar of Napari and select:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Cells (3D+2Ch)</code></p>
<p>You should see a fluorescence microscopy image of some cells:</p>
<figure><img src="../fig/cells-napari.png" alt="A screenshot of a flourescence microscopy image  of some cells in Napari" class="figure mx-auto d-block"></figure></section><section id="naparis-user-interface"><h2 class="section-heading">Napari’s User interface<a class="anchor" aria-label="anchor" href="#naparis-user-interface"></a>
</h2>
<hr class="half-width">
<p>Napari’s user interface is split into a few main sections, as you can
see in the diagram below (note that on Macs the main menu will appear in
the upper ribbon, rather than inside the Napari window):</p>
<figure><img src="../fig/ui-sections-napari.png" alt="A screenshot of Napari with the main user  interface sections labelled" class="figure mx-auto d-block"></figure><p>Let’s take a brief look at each of these sections - for full
information see the <a href="https://napari.org/stable/tutorials/fundamentals/viewer.html" class="external-link">Napari
documentation</a>.</p>
</section><section id="main-menu"><h2 class="section-heading">Main menu<a class="anchor" aria-label="anchor" href="#main-menu"></a>
</h2>
<hr class="half-width">
<p>We already used the main menu in the last section to open a sample
image. The main menu contains various commands for opening images,
changing preferences and installing plugins (we’ll see more of these
options in later episodes).</p>
</section><section id="canvas"><h2 class="section-heading">Canvas<a class="anchor" aria-label="anchor" href="#canvas"></a>
</h2>
<hr class="half-width">
<p>The canvas is the main part of the Napari user interface. This is
where we display and interact with our images.</p>
<p>Try moving around the cells image with the following commands:</p>
<pre><code>Pan - Click and drag
Zoom - Scroll in/out (use the same gestures with your mouse 
                      that you would use to scroll up/down 
                      in a document)</code></pre>
</section><section id="dimension-sliders"><h2 class="section-heading">Dimension sliders<a class="anchor" aria-label="anchor" href="#dimension-sliders"></a>
</h2>
<hr class="half-width">
<p>Dimension sliders appear at the bottom of the canvas depending on the
type of image displayed. For example, here we have a 3D image of some
cells, which consists of a stack of 2D images. If we drag the slider at
the bottom of the image, we move up and down in this stack:</p>
<figure><img src="../fig/dim-slider.png" alt="Three screenshots of the cells image in napari, at  different z depths" class="figure mx-auto d-block"></figure><p>Pressing the arrow buttons at either end of the slider steps through
one slice at a time. Also, pressing the ‘play’ button at the very left
of the slider moves automatically through the stack until pressed
again.</p>
<figure><img src="../fig/dim-slider-closeup.png" style="width:80.0%" alt="Closeup of Napari's dimension slider with labels" class="figure mx-auto d-block"></figure><p>We will see in later episodes that more sliders can appear if our
image has more dimensions (e.g. time series, or further channels).</p>
</section><section id="viewer-buttons"><h2 class="section-heading">Viewer buttons<a class="anchor" aria-label="anchor" href="#viewer-buttons"></a>
</h2>
<hr class="half-width">
<p>The viewer buttons (the row of buttons at the bottom left of Napari)
control various aspects of the Napari viewer:</p>
<div class="section level3">
<h3 id="console">Console <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/console.svg" alt="A screenshot of Napari's console button" height="30" class="figure"><a class="anchor" aria-label="anchor" href="#console"></a>
</h3>
<p>This button opens Napari’s built-in python console - we’ll look at
this in later episodes.</p>
</div>
<div class="section level3">
<h3 id="d3d">2D/3D <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/2D.svg" alt="A screenshot of Napari's 2D button" height="25" class="figure"> / <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/3D.svg" alt="A screenshot of Napari's 3D button" height="25" class="figure"><a class="anchor" aria-label="anchor" href="#d3d"></a>
</h3>
<p>This switches the canvas between 2D and 3D display. Try switching to
the 3D view for the cells image:</p>
<figure><img src="../fig/cells-3d-napari.png" alt="A screenshot of 3D cells in Napari" class="figure mx-auto d-block"></figure><p>The controls for moving in 3D are similar to those for 2D:</p>
<pre><code>Rotate - Click and drag
Pan - Shift + click and drag
Zoom - Scroll in/out</code></pre>
</div>
<div class="section level3">
<h3 id="roll-dimensions">Roll dimensions <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/roll.svg" alt="A screenshot of Napari's roll dimensions button" height="25" class="figure"><a class="anchor" aria-label="anchor" href="#roll-dimensions"></a>
</h3>
<p>This changes which image dimensions are displayed in the viewer. For
example, let’s switch back to the 2D view for our cells image and press
the roll dimensions button multiple times. You’ll see that it switches
between different orthogonal views (i.e. at 90 degrees to our starting
view). Pressing it 3 times will bring us back to the original
orientation.</p>
<figure><img src="../fig/roll-dims.png" alt="Three screenshots of the cells image in napari,  with different axes being visualised" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="transpose-dimensions">Transpose dimensions <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/transpose.svg" alt="A screenshot of Napari's transpose dimensions button" height="25" class="figure"><a class="anchor" aria-label="anchor" href="#transpose-dimensions"></a>
</h3>
<p>This button swaps the two currently displayed dimensions. Again
trying this for our cells image, we see that the image becomes flipped.
Pressing the button again brings us back to the original
orientation.</p>
<figure><img src="../fig/transpose-dim.png" alt="Two screenshots of the cells image in napari,  with dimensions swapped" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="grid">Grid <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/grid.svg" alt="A screenshot of Napari's grid button" height="25" class="figure"><a class="anchor" aria-label="anchor" href="#grid"></a>
</h3>
<p>This button displays all image layers in a grid (+ any additional
layer types, as we’ll see later in the episode). Using this for our
cells image, we see the nuclei (green) displayed next to the cell
membranes (purple), rather than on top of each other.</p>
</div>
<div class="section level3">
<h3 id="home">Home <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/home.svg" alt="A screenshot of Napari's home button" height="25" class="figure"><a class="anchor" aria-label="anchor" href="#home"></a>
</h3>
<p>This button brings the canvas back to its default view. This is
useful if you have panned/zoomed to a specific region and want to
quickly get back to an overview of the full image.</p>
</div>
</section><section id="layer-list"><h2 class="section-heading">Layer list<a class="anchor" aria-label="anchor" href="#layer-list"></a>
</h2>
<hr class="half-width">
<p>Now that we’ve seen the main controls for the viewer, let’s look at
the layer list. ‘Layers’ are how Napari displays multiple items together
in the viewer. For example, currently our layer list contains two items
- ‘nuclei’ and ‘membrane’. These are both <code>Image</code> layers and
are displayed in order, with the nuclei on top and membrane
underneath.</p>
<figure><img src="../fig/layer-list.png" alt="A screenshot of Napari's layer list, showing two  image layers named 'nuclei' and 'membrane'" class="figure mx-auto d-block"></figure><p>We can show/hide each layer by clicking the eye icon on the left side
of their row. We can also rename them by double clicking on the row.</p>
<p>We can change the order of layers by dragging and dropping items in
the layer list. For example, try dragging the membrane layer above the
nuclei. You should see the nuclei disappear from the viewer (as they are
now hidden by the membrane image on top).</p>
<figure><img src="../fig/layer-reordering.png" alt="A screenshot of Napari with the nuclei and  membrane layer swapped" class="figure mx-auto d-block"></figure><p>Here we only have <code>Image</code> layers, but there are many more
types like <code>Points</code>, <code>Shapes</code> and
<code>Labels</code>, some of which we will see later in the episode.</p>
</section><section id="layer-controls"><h2 class="section-heading">Layer controls<a class="anchor" aria-label="anchor" href="#layer-controls"></a>
</h2>
<hr class="half-width">
<p>Next let’s look at the layer controls - this area shows controls only
for the currently selected layer (i.e. the one that is highlighted in
blue in the layer list). For example, if we click on the nuclei layer
then we can see a <code>colormap</code> of green, while if we click on
the membrane layer we see a <code>colormap</code> of magenta.</p>
<p>Controls will also vary depending on layer type (like
<code>Image</code> vs <code>Points</code>) as we will see later in this
episode.</p>
<p>Let’s take a quick look at some of the main image layer controls:</p>
<div class="section level3">
<h3 id="opacity">Opacity<a class="anchor" aria-label="anchor" href="#opacity"></a>
</h3>
<p>This changes the opacity of the layer - lower values are more
transparent. For example, reducing the opacity of the membrane layer (if
it is still on top of the nuclei), allows us to see the nuclei
again.</p>
</div>
<div class="section level3">
<h3 id="contrast-limits">Contrast limits<a class="anchor" aria-label="anchor" href="#contrast-limits"></a>
</h3>
<p>We’ll discuss this in detail in a later episode, but briefly - the
contrast limits adjust what parts of the image we can see and how bright
they appear in the viewer. Moving the left node adjusts what is shown as
fully black, while moving the right node adjusts what is shown as fully
bright.</p>
</div>
<div class="section level3">
<h3 id="colormap">Colormap<a class="anchor" aria-label="anchor" href="#colormap"></a>
</h3>
<p>Again, we’ll discuss this in detail in a later episode, but briefly -
the colormap determines what colours an image is displayed with.
Clicking in the dropdown shows a wide range of options that you can swap
between.</p>
</div>
<div class="section level3">
<h3 id="blending">Blending<a class="anchor" aria-label="anchor" href="#blending"></a>
</h3>
<p>This controls how multiple layers are blended together to give the
final result in the viewer. There are <a href="https://napari.org/stable/guides/layers.html#blending-layers" class="external-link">many
different options to choose from</a>. For example, let’s put the nuclei
layer back on top of the membrane and change its blending to ‘opaque’.
You should see that it now completely hides the membrane layer
underneath. Changing the blending back to ‘additive’ will allow both the
nucleus and membrane layers to be seen together again.</p>
<div id="using-image-layer-controls" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="using-image-layer-controls" class="callout-inner">
<h3 class="callout-title">Using image layer controls<a class="anchor" aria-label="anchor" href="#using-image-layer-controls"></a>
</h3>
<div class="callout-content">
<p>Adjust the layer controls for both nuclei and membrane to give the
result below:</p>
<figure><img src="../fig/layer-controls-task.png" alt="Cells image with blue nuclei and bright  red membranes" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<ul>
<li>Click on the nuclei in the layer list</li>
<li>Change the colormap to cyan</li>
<li>Click on the membrane in the layer list</li>
<li>Change the colormap to red</li>
<li>Move the right contrast limits node to the left to make the
membranes appear brighter</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section><section id="layer-buttons"><h2 class="section-heading">Layer buttons<a class="anchor" aria-label="anchor" href="#layer-buttons"></a>
</h2>
<hr class="half-width">
<p>So far we have only looked at <code>Image</code> layers, but there
are many more types supported by Napari. The layer buttons allow us to
add additional layers of these new types:</p>
<div class="section level3">
<h3 id="points">Points <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/new_points.svg" alt="A screenshot of Napari's point layer button" height="30" class="figure"><a class="anchor" aria-label="anchor" href="#points"></a>
</h3>
<p>This button creates a new <a href="https://napari.org/stable/howtos/layers/points.html" class="external-link">points
layer</a>. This can be used to mark specific locations in an image.</p>
</div>
<div class="section level3">
<h3 id="shapes">Shapes <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/new_shapes.svg" alt="A screenshot of Napari's shape layer button" height="30" class="figure"><a class="anchor" aria-label="anchor" href="#shapes"></a>
</h3>
<p>This button creates a new <a href="https://napari.org/stable/howtos/layers/shapes.html" class="external-link">shapes
layer</a>. Shapes can be used to mark regions of interest e.g. with
rectangles, ellipses or lines.</p>
</div>
<div class="section level3">
<h3 id="labels">Labels <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/new_labels.svg" alt="A screenshot of Napari's labels layer button" height="30" class="figure"><a class="anchor" aria-label="anchor" href="#labels"></a>
</h3>
<p>This button creates a new <a href="https://napari.org/stable/howtos/layers/labels.html" class="external-link">labels
layer</a>. This is usually used to label specific regions in an image
e.g. to label individual nuclei.</p>
</div>
<div class="section level3">
<h3 id="remove-layer">Remove layer <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/delete.svg" alt="A screenshot of Napari's delete layer button" height="30" class="figure"><a class="anchor" aria-label="anchor" href="#remove-layer"></a>
</h3>
<p>This button removes the currently selected layer (highlighted in
blue) from the layer list.</p>
<div id="other-layer-types" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="other-layer-types" class="callout-inner">
<h3 class="callout-title">Other layer types<a class="anchor" aria-label="anchor" href="#other-layer-types"></a>
</h3>
<div class="callout-content">
<p>Note that there are some layer types that can’t be added via clicking
buttons in the user interface, like <a href="https://napari.org/stable/howtos/layers/surface.html" class="external-link">surfaces</a>,
<a href="https://napari.org/stable/howtos/layers/tracks.html" class="external-link">tracks</a>
and <a href="https://napari.org/stable/howtos/layers/vectors.html" class="external-link">vectors</a>.
These require calling python commands in Napari’s console or an external
python script.</p>
</div>
</div>
</div>
<div id="point-layers" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="point-layers" class="callout-inner">
<h3 class="callout-title">Point layers<a class="anchor" aria-label="anchor" href="#point-layers"></a>
</h3>
<div class="callout-content">
<p>Let’s take a quick look at one of these new layer types - the
<code>Points</code> layer.</p>
<p>Add a new points layer by clicking the points button. Investigate the
different layer controls - what do they do? Note that hovering over
buttons will usually show a summary tooltip.</p>
<p>Add points and adjust settings to give the result below:</p>
<figure><img src="../fig/points-task.png" alt="Cells image with points marking multiple nuclei" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ul>
<li>Click the ‘add points’ button <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/add.svg" alt="Screenshot of Napari's add points button" height="30" class="figure">
</li>
<li>Click on nuclei to add points on top of them</li>
<li>Click the ‘select points’ button <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/select.svg" alt="Screenshot of Napari's select points button" height="30" class="figure">
</li>
<li>Click on the point over the dividing nucleus</li>
<li>Increase the point size slider</li>
<li>Change its symbol to star</li>
<li>Change its face colour to purple</li>
<li>change its edge colour to white</li>
</ul>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Keypoints<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>There are many software options for light microscopy images</li>
<li>Napari and Fiji/ImageJ are popular open-source options</li>
<li>Napari’s user interface is split into a few main sections including
the canvas, layer list, layer controls…</li>
<li>Layers can be of different types e.g. <code>Image</code>,
<code>Point</code>, <code>Label</code>
</li>
<li>Different layer types have different layer controls</li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-what-is-an-image"><p>Content from <a href="what-is-an-image.html">What is an image?</a></p>
<hr>
<p> Last updated on 2024-01-15 | 
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/what-is-an-image.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time <i aria-hidden="true" data-feather="clock"></i> 40 minutes </p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right"> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How are images represented in the computer?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li><p>Explain how a digital image is made of pixels</p></li>
<li><p>Find the value of different pixels in an image in Napari</p></li>
<li><p>Determine an image’s dimensions (numpy ndarray
<code>.shape</code>)</p></li>
<li><p>Determine an image’s data type (numpy ndarray
<code>.dtype</code>)</p></li>
<li><p>Explain the coordinate system used for images</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In the last episode, we looked at how to view images in Napari. Let’s
take a step back now and try to understand how Napari (or ImageJ or any
other viewer) understands how to display images properly. To do that we
must first be able to answer the fundamental question - what is an
image?</p>
<section id="pixels"><h2 class="section-heading">Pixels<a class="anchor" aria-label="anchor" href="#pixels"></a>
</h2>
<hr class="half-width">
<p>Let’s start by removing all the layers we added to the Napari viewer
last episode. Then we can open a new sample image:</p>
<ul>
<li><p>Click on the top layer in the layer list and <kbd>shift</kbd> +
click the bottom layer. This should highlight all layers in
blue.</p></li>
<li><p>Press the remove layer button <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/delete.svg" alt="A screenshot of Napari's delete layer button" height="30" class="figure"></p></li>
<li><p>Go to the top menu-bar of Napari and select:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Human Mitosis</code></p></li>
</ul>
<figure><img src="../fig/human-mitosis-napari.png" alt="A screenshot of a 2D image of human cells  undergoing mitosis in Napari" class="figure mx-auto d-block"></figure><p>This 2D image shows the nuclei of human cells undergoing mitosis. If
we really zoom in up-close by scrolling, we can see that this image is
actually made up of many small squares with different brightness values.
These squares are the image’s pixels (or ‘picture elements’) and are the
individual units that make up all digital images.</p>
<p>If we hover over these pixels with the mouse cursor, we can see that
each pixel has a specific value. Try hovering over pixels in dark and
bright areas of the image and see how the value changes in the bottom
left of the viewer:</p>
<figure><img src="../fig/pixel-value.png" alt="A screenshot of Napari - with the mouse cursor  hovering over a pixel and highlighting the corresponding pixel value" class="figure mx-auto d-block"></figure><p>You should see that brighter areas have higher values than darker
areas (we’ll see exactly how these values are converted to colours in
the next episode).</p>
</section><section id="images-are-arrays-of-numbers"><h2 class="section-heading">Images are arrays of numbers<a class="anchor" aria-label="anchor" href="#images-are-arrays-of-numbers"></a>
</h2>
<hr class="half-width">
<p>We’ve seen that images are made of individual units called pixels
that have specific values - but how is an image really represented in
the computer? Let’s dig deeper into Napari’s <code>Image</code>
layers…</p>
<p>First, open Napari’s built-in Python console by pressing the console
button <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/console.svg" alt="A screenshot of Napari's console button" height="30" class="figure">. Note
this can take a few seconds to open, so give it some time:</p>
<figure><img src="../fig/console.png" alt="A screenshot of Napari's console" class="figure mx-auto d-block"></figure><div id="console-readability" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="console-readability" class="callout-inner">
<h3 class="callout-title">Console readability<a class="anchor" aria-label="anchor" href="#console-readability"></a>
</h3>
<div class="callout-content">
<p>You can increase the font size in the console by clicking inside it,
then pressing <kbd>Ctrl</kbd> and <kbd>+</kbd> together. The font size
can also be decreased with <kbd>Ctrl</kbd> and <kbd>-</kbd>
together.</p>
<p>Note that you can also pop the console out into its own window by
clicking the small <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/pop_out.svg" alt="A screenshot of Napari's float panel button" height="30" class="figure">
icon on the left side.</p>
</div>
</div>
</div>
<p>Let’s look at the human mitosis image more closely - copy the text in
the ‘Python’ cell below into Napari’s console and then press the
<kbd>Enter</kbd> key. You should see it returns text that matches the
‘Output’ cell below in response.</p>
<p>All of the information about the Napari viewer can be accessed
through the console with a variable called <code>viewer</code>. A
<code>viewer</code> has 1 to many layers, and here we access the top
(first) layer with <code>viewer.layers[0]</code>. Then, to access the
actual image data stored in that layer, we retrieve it with
<code>.data</code>:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the image data for the first layer in Napari</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="dv">0</span>].data</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the image values and type</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(image))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[ 8  8  8 ... 63 78 75]
 [ 8  8  7 ... 67 71 71]
 [ 9  8  8 ... 53 64 66]
 ...
 [ 8  9  8 ... 17 24 59]
 [ 8  8  8 ... 17 22 55]
 [ 8  8  8 ... 16 18 38]]
 
 &lt;class 'numpy.ndarray'&gt;</code></pre>
</div>
<p>You should see that a series of numbers are printed out that are
stored in a Python data type called a <code>numpy.ndarray</code>.
Fundamentally, this means that all images are really just arrays of
numbers (one number per pixel). Arrays are just rectangular grids of
numbers, much like a spreadsheet. Napari is reading those values and
converting them into squares of particular colours for us to see in the
viewer, but this is only to help us interpret the image contents - the
numbers are the real underlying data.</p>
<p>For example, look at the simplified image of an arrow below. On the
left is the array of numbers, with the corresponding image display on
the right. This is called a 4 by 4 image, as it has 4 rows and 4
columns:</p>
<figure><img src="../fig/array.png" alt="A diagram comparing the array of numbers and image  display for a simplified image of an arrow" class="figure mx-auto d-block"></figure><p>In Napari this array is a <code>numpy.ndarray</code>. <a href="https://numpy.org/" class="external-link">NumPy</a> is a popular python package that
provides ‘n-dimensional arrays’ (or ‘ndarray’ for short). N-dimensional
just means they can support any number of dimensions - for example, 2D
(squares/rectangles of numbers), 3D (cubes/cuboids of numbers) and
beyond (like time series, images with many channels etc. where we would
have multiple rectangles or cuboids of data which provide further
information all at the same location).</p>
</section><section id="creating-an-image"><h2 class="section-heading">Creating an image<a class="anchor" aria-label="anchor" href="#creating-an-image"></a>
</h2>
<hr class="half-width">
<p>Where do the numbers in our image array come from? The exact details
of how an image is created will depend on the type of microscope you are
using e.g.  widefield, confocal, superresolution etc. In general though,
we have 3 main parts:</p>
<ul>
<li>
<strong>Sample:</strong> the object we want to image e.g. some
cells</li>
<li>
<strong>Objective lens:</strong> the lens that gathers the light and
focuses it for detection</li>
<li>
<strong>Detector:</strong> the device that detects the light to form
the digital image e.g. a CCD camera</li>
</ul>
<p>To briefly summarise for a fluorescence microscopy image:<br>
an excitation light source (e.g. a laser) illuminates the sample, and
this light is absorbed by a fluorescent label. This causes it to emit
light which is then gathered and focused by the objective lens, before
hitting the detector. The detector might be a single element (e.g. in a
laser-scanning microscope) or composed of an array of many small, light
sensitive areas - these are physical pixels, that will correspond to the
pixels in the final image. When light hits one of the detector elements
it is converted into electrons, with more light resulting in more
electrons and a higher final value for that pixel.</p>
<p>The important factor to understand is that the final pixel value is
only ever an approximation of the real sample. Many factors will affect
this final result including the microscope optics, detector performance
etc.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Read the <a href="https://bioimagebook.github.io/chapters/1-concepts/1-images_and_pixels/images_and_pixels.html#a-simple-microscope" class="external-link">‘A
simple microscope’ section of Pete Bankhead’s bioimage book</a>.</p>
<ul>
<li>What are some factors that influence pixel values?</li>
<li>Can you come up with suggestions for any more?</li>
</ul>
</div>
</div>
</div>
</section><section id="image-dimensions"><h2 class="section-heading">Image dimensions<a class="anchor" aria-label="anchor" href="#image-dimensions"></a>
</h2>
<hr class="half-width">
<p>Let’s return to our human mitosis image and explore some of the key
features of its image array. First, what size is it?</p>
<p>We can find this out by running the following in Napari’s
console:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>image.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(512, 512)</code></pre>
</div>
<p>The array size (also known as its dimensions) is stored in the
<code>.shape</code>. Here we see that it is <code>(512, 512)</code>
meaning this image is 512 pixels high and 512 pixels wide. Two values
are printed as this image is two dimensional (2D), for a 3D image there
would be 3, for a 4D image (e.g. with an additional time series) there
would be 4 and so on…</p>
</section><section id="image-data-type"><h2 class="section-heading">Image data type<a class="anchor" aria-label="anchor" href="#image-data-type"></a>
</h2>
<hr class="half-width">
<p>The other key feature of an image array is its ‘data type’ - this
controls which values can be stored inside of it. For example, let’s
look at the data type for our human mitosis image - this is stored in
<code>.dtype</code>:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>image.dtype</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fu">dtype</span><span class="op">(</span><span class="st">'uint8'</span><span class="op">)</span></span></code></pre>
</div>
<p>We see that the data type (or ‘dtype’ for short) is
<code>uint8</code>. This is short for ‘unsigned integer 8-bit’. Let’s
break this down further into two parts - the type (unsigned integer) and
the bit-depth (8-bit).</p>
</section><section id="type"><h2 class="section-heading">Type<a class="anchor" aria-label="anchor" href="#type"></a>
</h2>
<hr class="half-width">
<p>The type determines what kind of values can be stored in the array,
for example:</p>
<ul>
<li>Unsigned integer: positive whole numbers</li>
<li>Signed integer: positive and negative whole numbers</li>
<li>Float: positive and negative numbers with a decimal point
e.g. 3.14</li>
</ul>
<p>For our mitosis image, ‘unsigned integer’ means that only positive
whole numbers can be stored inside. You can see this by hovering over
the pixels in the image again in Napari - the pixel value down in the
bottom left is always a positive whole number.</p>
</section><section id="bit-depth"><h2 class="section-heading">Bit depth<a class="anchor" aria-label="anchor" href="#bit-depth"></a>
</h2>
<hr class="half-width">
<p>The bit depth determines the range of values that can be stored
e.g. only values between 0 and 255. This is directly related to how the
array is stored in the computer.</p>
<p>In the computer, each pixel value will ultimately be stored in some
binary format as a series of ones and zeros. Each of these ones or zeros
is known as a ‘bit’, and the ‘bit depth’ is the number of bits used to
store each value. For example, our mitosis image uses 8 bits to store
each value (i.e.  a series of 8 ones or zeros like
<code>00000000</code>, or <code>01101101</code>…).</p>
<p>The reason the bit depth is so important is that it dictates the
number of different values that can be stored. In fact it is equal
to:</p>
<p><span class="math display">\[\large \text{Number of values} =
2^{\text{(bit depth)}}\]</span></p>
<p>Going back to our mitosis image, since it is stored as integers with
a bit-depth of 8, this means that it can store <span class="math inline">\(2^8 = 256\)</span> different values. This is equal
to a range of 0-255 for unsigned integers.</p>
<p>We can verify this by looking at the maximum value of the mitosis
image:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image.<span class="bu">max</span>())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fl">255</span></span></code></pre>
</div>
<p>You can also see this by hovering over the brightest nuclei in the
viewer and examining their pixel values. Even the brightest nuclei won’t
exceed the limit of 255.</p>
<div id="dimensions-and-data-types" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="dimensions-and-data-types" class="callout-inner">
<h3 class="callout-title">Dimensions and data types<a class="anchor" aria-label="anchor" href="#dimensions-and-data-types"></a>
</h3>
<div class="callout-content">
<p>Let’s open a new image by removing all layers from the Napari viewer,
then copying and pasting the following lines into the Napari
console:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage <span class="im">import</span> data</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>viewer.add_image(data.brain()[<span class="dv">9</span>, :, :], name<span class="op">=</span><span class="st">"brain"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"brain"</span>].data</span></code></pre>
</div>
<p>This opens a new 2D image of part of a human head X-ray.</p>
<ul>
<li><p>What are the dimensions of this image?</p></li>
<li><p>What type and bit depth is this image?</p></li>
<li><p>What are the possible min/max values of this image array, based
on the bit depth?</p></li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="section level3">
<h3 id="dimensions">Dimensions<a class="anchor" aria-label="anchor" href="#dimensions"></a>
</h3>
<p>The image’s dimensions are (256, 256)</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>image.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
(256, 256)</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="type-and-bit-depth">Type and bit depth<a class="anchor" aria-label="anchor" href="#type-and-bit-depth"></a>
</h3>
<p>The image’s type and bit depth are: unsigned integer 16-bit</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>image.dtype</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fu">dtype</span><span class="op">(</span><span class="st">'uint16'</span><span class="op">)</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="min-and-max">Min and max<a class="anchor" aria-label="anchor" href="#min-and-max"></a>
</h3>
<p>Based on a bit depth of 16, this image can store <span class="math inline">\(2^{16} = 65536\)</span> values. As it is of type
‘unsigned integer’ this corresponds to a min and max of 0 and 65535.</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="common-data-types"><h2 class="section-heading">Common data types<a class="anchor" aria-label="anchor" href="#common-data-types"></a>
</h2>
<hr class="half-width">
<p>NumPy supports a <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#sized-aliases" class="external-link">very
wide range of data types</a>, but there are a few that are most common
for image data:</p>
<table class="table">
<thead><tr class="header">
<th align="left">NumPy datatype</th>
<th align="left">Full name</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>uint8</code></td>
<td align="left">Unsigned integer 8-bit</td>
</tr>
<tr class="even">
<td align="left"><code>uint16</code></td>
<td align="left">Unsigned integer 16-bit</td>
</tr>
<tr class="odd">
<td align="left"><code>float32</code></td>
<td align="left">Float 32-bit</td>
</tr>
<tr class="even">
<td align="left"><code>float64</code></td>
<td align="left">Float 64-bit</td>
</tr>
</tbody>
</table>
<p><code>uint8</code> and <code>uint16</code> are most common for images
from light microscopes. <code>float32</code> and <code>float64</code>
are common during image processing (as we will see in later
episodes).</p>
</section><section id="choosing-a-bit-depth"><h2 class="section-heading">Choosing a bit depth<a class="anchor" aria-label="anchor" href="#choosing-a-bit-depth"></a>
</h2>
<hr class="half-width">
<p>Most images are either 8-bit or 16-bit - so how to choose which to
use? A higher bit depth will allow a wider range of values to be stored,
but it will also result in larger file sizes for the resulting images.
In general, a 16-bit image will have a file size that is about twice as
large as an 8-bit image if no compression is used (we’ll discuss
compression in a later episode).</p>
<p>The best bit depth choice will depend on your particular imaging
experiment and research question. For example, if you know you have to
recognise features that only differ slightly in their brightness, then
you will likely need 16-bit to capture this. Equally, if you know that
you will need to collect a very large number of images and 8-bit is
sufficient to see your features of interest, then 8-bit may be a better
choice to reduce the required file storage space. As always it’s about
choosing the best fit for your specific project!</p>
<p>For more information on bit depths and types - we highly recommend <a href="https://bioimagebook.github.io/chapters/1-concepts/3-bit_depths/bit_depths.html" class="external-link">the
‘Types &amp; bit-depths’ chapter from Pete Bankhead’s free bioimage
book</a>.</p>
<div id="clipping-and-overflow" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="clipping-and-overflow" class="callout-inner">
<h3 class="callout-title">Clipping and overflow<a class="anchor" aria-label="anchor" href="#clipping-and-overflow"></a>
</h3>
<div class="callout-content">
<p>It’s important to be aware of what image type and bit depth you are
using. If you try to store values outside of the valid range, this can
lead to <em>clipping</em> and <em>overflow</em>.</p>
<ul>
<li><p>Clipping: Values outside the valid range are changed to the
closest valid value. For example, storing 1000 in a <code>uint8</code>
image may result in 255 being stored instead (the max value)</p></li>
<li><p>Overflow: For NumPy arrays, values outside the valid range are
‘wrapped around’ to give the new result. For example, storing 256 in a
<code>uint8</code> image (max 255) would give 0, 257 would give 1 and so
on…</p></li>
</ul>
<p>Clipping and overflow result in data loss - you can’t get the
original values back! So it’s always good to keep the data type in mind
when doing image processing operations (as we will see in later
episodes), and also when converting between different bit depths.</p>
</div>
</div>
</div>
</section><section id="coordinate-system"><h2 class="section-heading">Coordinate system<a class="anchor" aria-label="anchor" href="#coordinate-system"></a>
</h2>
<hr class="half-width">
<p>We’ve seen that images are arrays of numbers with a specific shape
(dimensions) and data type. How do we access specific values from this
array? What coordinate system is Napari using?</p>
<p>To look into this, let’s hover over pixels in our mitosis image and
examine the coordinates that appear to the left of the pixel value. If
you closed the mitosis image, then open it again by removing all layers
and selecting:
<code>File &gt; Open Sample &gt; napari builtins &gt; Human Mitosis</code>:</p>
<figure><img src="../fig/coordinates.png" alt="A screenshot of Napari - with the mouse cursor  hovering over a pixel and highlighting the corresponding coordinates" class="figure mx-auto d-block"></figure><p>As you move around, you should see that the lowest coordinate values
are at the top left corner, with the first value increasing as you move
down and the second value increasing as you move to the right. This is
different to the standard coordinate systems you may be used to (for
example, from making graphs):</p>
<figure><img src="../fig/coordinate-system.png" alt="Diagram comparing a standard graph  coordinate system (left) and the image coordinate system (right)" class="figure mx-auto d-block"></figure><p>Note that Napari lists coordinates as [y, x] or [rows, columns], so
e.g. [1,3] would be the pixel in row 1 and column 3. Remember that these
coordinates always start from 0 as you can see in the diagram below:</p>
<figure><img src="../fig/coordinates-on-image.png" style="width:50.0%" alt="A diagram showing how pixel coordinates change over a simple 4x4 image" class="figure mx-auto d-block"></figure><p>For the mitosis image, these coordinates are in pixels, but we’ll see
in later episodes that images can also be scaled based on resolution to
represent distances in the physical world (e.g. in micrometres). Also,
bear in mind that images with more dimensions (e.g. a 3D image) will
have longer coordinates like [z, y, x]…</p>
<div id="reading-and-modifying-pixel-values" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="reading-and-modifying-pixel-values" class="callout-inner">
<h3 class="callout-title">Reading and modifying pixel values<a class="anchor" aria-label="anchor" href="#reading-and-modifying-pixel-values"></a>
</h3>
<div class="callout-content">
<p>First, make sure you only have the human mitosis image open (close
any others). Run the following line in the console to ensure you are
referencing the correct image:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the image data for the layer called 'human_mitosis'</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"human_mitosis"</span>].data</span></code></pre>
</div>
<p>Pixel values can be read by hovering over them in the viewer, or by
running the following in the console:</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace y and x with the correct y and x coordinate e.g. image[3, 5]</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image[y, x])</span></code></pre>
</div>
<p>Pixel values can be changed by running the following in the
console:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace y and x with the correct y and x coordinate, and</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 'pixel_value' with the desired new pixel value e.g. image[3, 5] = 10</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>image[y, x] <span class="op">=</span> pixel_value</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>viewer.layers[<span class="st">"human_mitosis"</span>].refresh()</span></code></pre>
</div>
<p>Given this information:</p>
<ol style="list-style-type: decimal">
<li>What is the pixel value at x=213 and y=115?</li>
<li>What is the pixel value at x=25 and y=63?</li>
<li>Change the value of the pixel at x=10 and y=15 to 200. Check the new
value - is it correct? If not, why not?</li>
<li>Change the value of the pixel at x=10 and y=15 to 300. Check the new
value - is it correct? If not, why not?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<div class="section level3">
<h3 id="section">1<a class="anchor" aria-label="anchor" href="#section"></a>
</h3>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>image[<span class="dv">115</span>, <span class="dv">213</span>]</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fl">162</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="section-1">2<a class="anchor" aria-label="anchor" href="#section-1"></a>
</h3>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>image[<span class="dv">63</span>, <span class="dv">25</span>]</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fl">9</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="section-2">3<a class="anchor" aria-label="anchor" href="#section-2"></a>
</h3>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>image[<span class="dv">15</span>, <span class="dv">10</span>] <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>viewer.layers[<span class="st">"human_mitosis"</span>].refresh()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image[<span class="dv">15</span>, <span class="dv">10</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fl">200</span></span></code></pre>
</div>
<p>The new value is correct. If you zoom into the top left corner of the
image, you should see the one bright pixel you just created.</p>
</div>
<div class="section level3">
<h3 id="section-3">4<a class="anchor" aria-label="anchor" href="#section-3"></a>
</h3>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>image[<span class="dv">15</span>, <span class="dv">10</span>] <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>viewer.layers[<span class="st">"human_mitosis"</span>].refresh()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image[<span class="dv">15</span>, <span class="dv">10</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span></span>
<span><span class="fl">44</span></span></code></pre>
</div>
<p>The new value is not correct. This is because 300 exceeds the maximum
value for this 8-bit image (max 255). The value therefore overflows and
‘wraps around’ to give 44 - an incorrect value.</p>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Keypoints<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Digital images are made of pixels</li>
<li>Digital images store these pixels as arrays of numbers</li>
<li>Light microscopy images are only an approximation of the real
sample</li>
<li>Napari (and Python more widely) use NumPy arrays to store images -
these have a <code>shape</code> and <code>dtype</code>
</li>
<li>Most images are 8-bit or 16-bit unsigned integer</li>
<li>Images use a coordinate system with (0,0) at the top left, x
increasing to the right, and y increasing down</li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-image-display"><p>Content from <a href="image-display.html">Image display</a></p>
<hr>
<p> Last updated on 2024-01-31 | 
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/image-display.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time <i aria-hidden="true" data-feather="clock"></i> 40 minutes </p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right"> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How are pixel values converted into colours for display?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Create a histogram for an image</li>
<li>Install plugins from Napari Hub</li>
<li>Change colormap (LUT) in Napari</li>
<li>Adjust brightness and contrast in Napari</li>
<li>Explain the importance of always retaining a copy of the original
pixel values</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="image-array-and-display"><h2 class="section-heading">Image array and display<a class="anchor" aria-label="anchor" href="#image-array-and-display"></a>
</h2>
<hr class="half-width">
<p>Last episode we saw that images are arrays of numbers with specific
dimensions and data type. Napari reads these numbers (pixel values) and
converts them into colours on our display, allowing us to view the
image. Exactly how this conversion is done can vary greatly, and is the
topic of this episode.</p>
<p>For example, take the image array shown below. Depending on the
display settings, it can look very different inside Napari:</p>
<figure><img src="../fig/same-array-diff-display.png" style="width:70.0%" alt="Diagram showing an image array (top) with three different colormap  options (bottom)" class="figure mx-auto d-block"></figure><p>Equally, image arrays with different pixel values can look the same
in Napari depending on the display settings:</p>
<figure><img src="../fig/diff-array-same-display.png" style="width:50.0%" alt="Diagram showing two image arrays - 8-bit vs 16-bit (top) with the same  display (bottom)" class="figure mx-auto d-block"></figure><p>In summary, we can’t rely on appearance alone to understand the
underlying pixel values. Display settings (like the colormap, brightness
and contrast - as we will see below) have a big impact on how the final
image looks.</p>
</section><section id="napari-plugins"><h2 class="section-heading">Napari plugins<a class="anchor" aria-label="anchor" href="#napari-plugins"></a>
</h2>
<hr class="half-width">
<p>How can we quickly assess the pixel values in an image? We could
hover over pixels in Napari, or print the array into Napari’s console
(as we saw last episode), but these are hard to interpret at a glance. A
much better option is to use an image histogram.</p>
<p>To do this, we will have to install a new plugin for Napari. Remember
from the <a href="imaging-software.html">Imaging Software episode</a>
that plugins add new features to a piece of software. Napari has
hundreds of plugins available on the <a href="https://www.napari-hub.org/" class="external-link">napari hub</a> website.</p>
<p>Let’s start by going to the napari hub and searching for
‘matplotlib’:</p>
<figure><img src="../fig/napari-hub.png" alt="Screenshot of searching 'matplotlib' on napari hub" class="figure mx-auto d-block"></figure><p>You should see ‘napari Matplotlib’ appear in the list (if not, try
scrolling further down the page). If we click on
<code>napari matplotlib</code> this opens a summary of the plugin with
links to the documentation. There’s also a useful ‘Activity’ tab that
summarises the number of installs and maintenance history of the
plugin:</p>
<figure><img src="../fig/napari-hub-activity.png" alt="Screenshot of napari-matplotlib's activity tab on napari hub" class="figure mx-auto d-block"></figure><p>Now that we’ve found the plugin we want to use, let’s go ahead and
install it in Napari. Note that some plugins have special requirements
for installation, so it’s always worth checking their napari hub page
for any extra instructions. In the top menu bar of Napari select:<br><code>Plugins &gt; Install/Uninstall Plugins...</code></p>
<figure><img src="../fig/plugin-installation.png" alt="Screenshot of plugin installation window in Napari" class="figure mx-auto d-block"></figure><p>This should open a window summarising all installed plugins (at the
top) and all available plugins to install (at the bottom). If we search
for ‘matplotlib’ in the top searchbar, then ‘napari-matplotlib’ will
appear under ‘Available Plugins’. Press the blue install button and wait
for it to finish. <strong>You’ll then need to close and re-open
Napari.</strong></p>
<p>If all worked as planned, you should see a new option in the top
menubar under:<br><code>Plugins &gt; napari Matplotlib</code></p>
<div id="finding-plugins" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="finding-plugins" class="callout-inner">
<h3 class="callout-title">Finding plugins<a class="anchor" aria-label="anchor" href="#finding-plugins"></a>
</h3>
<div class="callout-content">
<p>Napari hub contains hundreds of plugins with varying quality, written
by many different developers. It can be difficult to choose which
plugins to use!</p>
<ul>
<li>Search for cell tracking plugins on <a href="https://www.napari-hub.org/" class="external-link">Napari hub</a>
</li>
<li>Look at some of the plugin summaries and ‘Activity’ tabs</li>
<li>What factors could help you decide if the plugin is well
maintained?</li>
<li>What factors could help you decide if the plugin is popular with
Napari users?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="section level3">
<h3 id="is-a-plugin-well-maintained">Is a plugin well maintained?<a class="anchor" aria-label="anchor" href="#is-a-plugin-well-maintained"></a>
</h3>
<p>Some factors to look for:</p>
<p><strong>Last updated</strong><br>
Check when the plugin was last updated - was it recently? This is shown
in the search list summary and under ‘Maintenance’ in the activity tab.
In the activity tab, you can also look at a graph summarising the
‘commits’ over the past year - ‘commits’ are made when someone updates
their plugin with new changes.</p>
<p><strong>Documentation</strong><br>
Is the plugin summary (+ any linked documentation) detailed enough to
explain how to use the plugin?</p>
</div>
<div class="section level3">
<h3 id="is-a-plugin-popular">Is a plugin popular?<a class="anchor" aria-label="anchor" href="#is-a-plugin-popular"></a>
</h3>
<p>Some factors to look for:</p>
<p><strong>Installs</strong><br>
Check how many times a plugin has been installed - a higher number of
installs usually means it’s more popular in the Napari community. The
installs are shown in the search list summary and under ‘Usage’ in the
activity tab. In the activity tab, you can also look at a graph
summarising the installs over the past year.</p>
<p><strong>Image.sc</strong><br>
It can also be useful to search the plugin’s name on the <a href="https://forum.image.sc/" class="external-link">image.sc</a> forum to browse relevant
posts and see if other people had good experiences using it. Image.sc is
also a great place to get help and advice from other plugin users, or
the plugin’s developers.</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="image-histograms"><h2 class="section-heading">Image histograms<a class="anchor" aria-label="anchor" href="#image-histograms"></a>
</h2>
<hr class="half-width">
<p>Let’s use our newly installed plugin to look at the human mitosis
image. If you don’t have it open, go the top menubar and select:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Human Mitosis</code></p>
<p>Then open the image histogram with:<br><code>Plugins &gt; napari Matplotlib &gt; Histogram</code></p>
<p>You should see a histogram open on the right side of the image:</p>
<figure><img src="../fig/mitosis-histogram.png" style="width:70.0%" alt="Screenshot of image histogram for mitosis image" class="figure mx-auto d-block"></figure><p>This histogram summarises the pixel values of the entire image. On
the x axis is the pixel value which run from 0-255 for this 8-bit image.
This is split into a number of ‘bins’ of a certain width (for example,
it could be 0-10, 11-20 and so on…). Each bin has a blue bar whose
height represents the number of pixels with values in that bin. So, for
example, for our mitosis image we see the highest bars to the left, with
shorter bars to the right. This means this image has a lot of very dark
(low intensity) pixels and fewer bright (high intensity) pixels.</p>
<p>The vertical white lines at 0 and 255 represent the current ‘contrast
limits’ - we’ll look at this in detail in a <a href="#brightness-and-contrast">later section of this episode</a>.</p>
<p>Let’s quickly compare to another image. Open the ‘coins’ image
with:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Coins</code></p>
<figure><img src="../fig/coins-histogram.png" style="width:68.0%" alt="Screenshot of image histogram for coins image" class="figure mx-auto d-block"></figure><p>From the histogram, we can see that this image has a wider spread of
pixel values. There are bars of similar height across many different
values (rather than just one big peak at the left hand side).</p>
<p>Image histograms are a great way to quickly summarise and compare
pixel values of different images.</p>
<div id="histograms" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="histograms" class="callout-inner">
<h3 class="callout-title">Histograms<a class="anchor" aria-label="anchor" href="#histograms"></a>
</h3>
<div class="callout-content">
<p>Match each of these small test images to their corresponding
histogram. You can assume that all images are displayed with a standard
gray colormap and default contrast limits of the min/max possible pixel
values:</p>
<figure><img src="../fig/exercise-hist-images.png" style="width:68.0%" alt="Screenshot of 4 small grayscale test images" class="figure mx-auto d-block"></figure><figure><img src="../fig/exercise-histograms.png" alt="Screenshot of 4 histograms, corresponding to the test images" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ul>
<li>a - 3</li>
<li>b - 4</li>
<li>c - 2</li>
<li>d - 1</li>
</ul>
</div>
</div>
</div>
</div>
</section><section id="changing-display-settings"><h2 class="section-heading">Changing display settings<a class="anchor" aria-label="anchor" href="#changing-display-settings"></a>
</h2>
<hr class="half-width">
<p>What happens to pixel values when we change the display settings? Try
changing the contrast limits or colormap in the layer controls. You
should see that the blue bars of the histogram stay the same, no matter
what settings you change i.e. the display settings don’t affect the
underlying pixel values.</p>
<p>This is one of the reasons it’s <em>important to use software
designed for scientific analysis</em> to work with your light microscopy
images. Software like Napari and ImageJ will try to ensure that your
pixel values remain unchanged, while other image editing software
(designed for working with photographs) may change the pixel values in
unexpected ways. Also, even with scientific software, some image
processing steps (that we’ll see in later episodes) will change the
pixel values.</p>
<p>Keep this in mind and make sure you always retain a copy of your
original data, in its original file format! We’ll see in the <a href="./FIXME.html">‘Filetypes and metadata’ episode</a> that original
image files contain important metadata that should be kept for future
reference.</p>
</section><section id="colormaps-luts"><h2 class="section-heading">Colormaps / LUTs<a class="anchor" aria-label="anchor" href="#colormaps-luts"></a>
</h2>
<hr class="half-width">
<p>Let’s dig deeper into Napari’s colormaps. As we saw in the <a href="what-is-an-image.html">‘What is an image?’ episode</a>, images are
represented by arrays of numbers (pixel values) with certain dimensions
and data type. Napari (or any other image viewer) has to convert these
numbers into coloured squares on our screen to allow us to view and
interpret the image. Colormaps (also known as lookup tables or LUTs) are
a way to convert pixel values into corresponding colours for display.
For example, remember the image at the beginning of this episode,
showing an image array using three different colormaps:</p>
<figure><img src="../fig/same-array-diff-display.png" style="width:70.0%" alt="Diagram showing an image array (top) with three different colormap  options (bottom)" class="figure mx-auto d-block"></figure><p>Napari supports a wide range of colormaps that can be selected from
the ‘colormap’ menu in the layer controls (as we saw in the <a href="imaging-software.html">Imaging Software episode</a>). For example,
see the diagram below showing the ‘gray’ colormap, where every pixel
value from 0-255 is matched to a shade of gray:</p>
<figure><img src="../fig/gray-colorbar.png" style="width:50.0%" alt="Grey colormap shown as a colorbar with corresponding pixel values" class="figure mx-auto d-block"></figure><p>See the diagram below for examples of 4 different colormaps applied
to the ‘coins’ image from Napari, along with corresponding image
histograms:</p>
<figure><img src="../fig/colorbar-comparison.png" style="width:90.0%" alt="Diagram showing histograms, colorbars and images for the gray, green,  viridis and inferno colormap applied on the coins image" class="figure mx-auto d-block"></figure><p>Why would we want to use different colormaps?</p>
<ul>
<li>to highlight specific features in an image</li>
<li>to help with overlaying multiple images, as we saw in the <a href="imaging-software.html">Imaging Software episode</a> when we
displayed green nuclei and magenta membranes together.</li>
<li>to help interpretation of an image. For example, if we used a red
fluorescent label in an experiment, then using a red colormap might help
people understand the image quickly.</li>
</ul></section><section id="brightness-and-contrast"><h2 class="section-heading">Brightness and contrast<a class="anchor" aria-label="anchor" href="#brightness-and-contrast"></a>
</h2>
<hr class="half-width">
<p>As the final section of this episode, let’s learn more about the
‘contrast limits’ in Napari. As we saw in the <a href="imaging-software.html">Imaging Software episode</a>, adjusting the
contrast limits in the layer controls changes how bright different parts
of the image are displayed. What is really going on here though?</p>
<p>In fact, the ‘contrast limits’ are adjusting how our colormap gets
applied to the image. For example, consider the standard gray
colormap:</p>
<figure><img src="../fig/contrast-comparison-0-255.png" style="width:90.0%" alt="Histogram, colorbar and image corresponding to coins coloured by the  gray colormap. Contrast limits 0 and 255." class="figure mx-auto d-block"></figure><p>For an 8-bit image, the range of colours from black to white are
normally spread from 0 (the minimum pixel value) to 255 (the maximum
pixel value). If we move the left contrast limits node, we change where
the colormap starts from e.g.  for a value of 150 we get:</p>
<figure><img src="../fig/contrast-comparison-150-255.png" style="width:90.0%" alt="Histogram, colorbar and image corresponding to coins coloured by the  gray colormap. Contrast limits 150 and 255." class="figure mx-auto d-block"></figure><p>Now all the colours from black to white are spread over a smaller
range of pixel values from 150-255 and everything below 150 is set to
black. Note that in Napari you can set specific values for the contrast
limits by right clicking on the contrast limits slider. As you adjust
the contrast limits, the vertical white lines on the
<code>napari-matplotlib</code> histogram will move to match.</p>
<p>If we move the right contrast limits node, we change where the
colormap ends (i.e. where pixels are fully white). For example, for
contrast limits of 150 and 200:</p>
<figure><img src="../fig/contrast-comparison-150-200.png" style="width:90.0%" alt="Histogram, colorbar and image corresponding to coins coloured by the  gray colormap. Contrast limits 150 and 200." class="figure mx-auto d-block"></figure><p>Now the range of colours from black to white only cover the pixel
values from 150-200, everything below is black and everything above is
white.</p>
<p>Why do we need to adjust contrast limits?</p>
<ul>
<li><p>to allow us to see low contrast features. Some parts of your
image may only differ slightly in their pixel value (low contrast).
Bringing the contrast limits closer together allows a small change in
pixel value to be represented by a bigger change in colour from the
colormap.</p></li>
<li><p>to focus on specific features. For example, increasing the lower
contrast limit will remove any low intensity parts of the image from the
display.</p></li>
</ul>
<div id="adjusting-contrast" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="adjusting-contrast" class="callout-inner">
<h3 class="callout-title">Adjusting contrast<a class="anchor" aria-label="anchor" href="#adjusting-contrast"></a>
</h3>
<div class="callout-content">
<p>Open the Napari console with the <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/console.svg" alt="A screenshot of Napari's console button" height="30" class="figure"> button
and copy and paste the code below:</p>
<pre><code>import numpy as np
from skimage.draw import disk
image = np.full((100,100), 10, dtype="uint8")
image[:, 50:100] = 245
image[disk((50, 25),15)] = 11
image[disk((50, 75),15)] = 247
viewer.add_image(image)</code></pre>
<p>This 2D image contains two hidden circles:</p>
<ul>
<li>Adjust Napari’s contrast limits to view both</li>
<li>What contrast limits allow you to see each circle? (remember you can
right click on the contrast limit bar to see specific values). Why do
these limits work?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>The left circle can be seen with limits of e.g. 0 and 33</p>
<p>These limits work because the background on the left side of the
image has a pixel value of 10 and the circle has a value of 11. By
moving the upper contrast limit to the left we force the colormap to go
from black to white over a smaller range of pixel values. This allows
this small difference in pixel value to be represented by a larger
difference in colour and therefore made visible.</p>
<p>The right circle can be seen with limits of e.g. 231 and 255. This
works for a very similar reason - the background has a pixel value of
245 and the circle has a value of 247.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Keypoints<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>The same image array can be displayed in many different ways in
Napari</li>
<li>Image histograms provide a useful overview of the pixel values in an
image</li>
<li>Plugins can be searched for on Napari hub and installed via
Napari</li>
<li>Colormaps (or LUTs) map pixel values to colours</li>
<li>Contrast limits change the range of pixel values the colormap is
spread over</li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-multi-dimensional-images"><p>Content from <a href="multi-dimensional-images.html">Multi-dimensional images</a></p>
<hr>
<p> Last updated on 2023-12-20 | 
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/multi-dimensional-images.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time <i aria-hidden="true" data-feather="clock"></i> 40 minutes </p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right"> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do we visualise and work with images with more than 2
dimensions?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain how different axes (xyz, channels, time) are stored in image
arrays and displayed</li>
<li>Open and navigate images with different dimensions in Napari</li>
<li>Explain what RGB images are and how they are handled in Napari</li>
<li>Split and merge channels in Napari</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="image-dimensions-axes"><h2 class="section-heading">Image dimensions / axes<a class="anchor" aria-label="anchor" href="#image-dimensions-axes"></a>
</h2>
<hr class="half-width">
<p>As we saw in the <a href="what-is-an-image.html">‘What is an image?’
episode</a>, image pixel values are stored as arrays of numbers with
certain dimensions and data type. So far we have focused on grayscale 2D
images that are represented by a 2D array:</p>
<figure><img src="../fig/array.png" style="width:80.0%" alt="A diagram comparing the array of numbers and image  display for a simplified image of an arrow" class="figure mx-auto d-block"></figure><p>Light microscopy data varies greatly though, and often has more
dimensions representing:</p>
<ul>
<li><p><strong>Time (t):</strong><br>
Multiple images of the same sample over a certain time period - also
known as a ‘time series’. This is useful to evaluate dynamic
processes.</p></li>
<li><p><strong>Channels (c):</strong><br>
Usually, this is multiple images of the same sample under different
wavelengths of light (e.g. red, green, blue channels, or wavelengths
specific to certain fluorescent markers). Note that channels can
represent many more values though, as we will <a href="#channels">see
below</a>.</p></li>
<li><p><strong>Depth (z):</strong><br>
Multiple images of the same sample, taken at different depths. This will
produce a 3D volume of images, allowing the shape and position of
objects to be understood in full 3D.</p></li>
</ul>
<p>These images will be stored as arrays that have more than two
dimensions. Let’s start with our familiar human mitosis image, and work
up to some more complex imaging data.</p>
</section><section id="d"><h2 class="section-heading">2D<a class="anchor" aria-label="anchor" href="#d"></a>
</h2>
<hr class="half-width">
<p>Go to the top menu-bar of Napari and select:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Human Mitosis</code></p>
<figure><img src="../fig/human-mitosis-napari.png" alt="A screenshot of a 2D image of human cells  undergoing mitosis in Napari" class="figure mx-auto d-block"></figure><p>We can see this image only has two dimensions (or two ‘axes’ as
they’re also known) due to the lack of sliders under the image, and by
checking its shape in the Napari console. Remember that we looked at <a href="what-is-an-image.html#images-are-arrays-of-numbers">how to open
the console</a> and how to check the <a href="what-is-an-image.html#image-dimensions"><code>.shape</code></a> in
detail in the <a href="what-is-an-image.html">‘What is an image?’
episode</a>:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"human_mitosis"</span>].data</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># (y, x)
(512, 512)</code></pre>
</div>
<p>Note that comments have been added to all output sections in this
episode (the lines starting with #). These state what the dimensions
represent (e.g. (y, x) for the y and x axes). These comments won’t
appear in the output in your console.</p>
</section><section id="d-1"><h2 class="section-heading">3D<a class="anchor" aria-label="anchor" href="#d-1"></a>
</h2>
<hr class="half-width">
<p>Let’s remove the mitosis image by clicking the remove layer button
<img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/delete.svg" alt="A screenshot of Napari's delete layer button" height="30" class="figure"> at
the top right of the layer list. Then, let’s open a new 3D image:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Brain (3D)</code></p>
<figure><img src="../fig/brain-napari.png" alt="A screenshot of a head X-ray in Napari" class="figure mx-auto d-block"></figure><p>This image shows part of a human head acquired using X-ray
Computerised Tomography (CT). We can see it has three dimensions due to
the slider at the base of the image, and the shape output:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"brain"</span>].data</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># (z, y, x)
(10, 256, 256)</code></pre>
</div>
<p>This 3D image can be thought of as a stack of ten 2D images, with
each image containing a 256x256 array. The x/y axes point along the
width/height of the first 2D image, and the z axis points along the
stack. It is stored as a 3D array:</p>
<figure><img src="../fig/2d-3d-arrays.png" style="width:80.0%" alt="A diagram comparing 2D and  3D image arrays" class="figure mx-auto d-block"></figure><p>In Napari (and Python in general), dimensions are referred to by
their index e.g. here dimension 0 is the z axis, dimension 1 is the y
axis and dimension 2 is the x axis. We can check this in Napari by
looking at the number at the very left of the slider. Here it’s labelled
‘0’, showing that it controls movement along dimension 0 (i.e. the z
axis).</p>
<div id="axis-labels" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="axis-labels" class="callout-inner">
<h3 class="callout-title">Axis labels<a class="anchor" aria-label="anchor" href="#axis-labels"></a>
</h3>
<div class="callout-content">
<p>By default, sliders will be labelled by the index of the dimension
they move along e.g. 0, 1, 2… Note that it is possible to re-name these
though! For example, if you click on the number at the left of the
slider, you can freely type in a new value. This can be useful to label
sliders with informative names like ‘z’, or ‘time’.</p>
<p>You can also check which labels are currently being used with:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>viewer.dims.axis_labels</span></code></pre>
</div>
</div>
</div>
</div>
</section><section id="channels"><h2 class="section-heading">Channels<a class="anchor" aria-label="anchor" href="#channels"></a>
</h2>
<hr class="half-width">
<p>Next, let’s look at a 3D image where an additional (fourth) dimension
contains data from different ‘channels’. Remove the brain image and
select:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Cells (3D+2Ch)</code></p>
<figure><img src="../fig/cells-napari.png" alt="A screenshot of a flourescence microscopy image  of some cells in Napari" class="figure mx-auto d-block"></figure><p>Image channels can be used to store data from multiple sources for
the same location. For example, consider the diagram below. On the left
is shown a 2D image array overlaid on a simple cell with a nucleus. Each
of the pixel locations e.g. (0, 0), (1, 1), (2, 1)… can be considered as
sampling locations where different measurements can be made. For
example, this could be the intensity of light detected with different
wavelengths (like red, green…) at each location, or it could be
measurements of properties like the surface height and elasticity at
each location (like from <a href="https://www.nature.com/articles/s43586-021-00033-2" class="external-link">scanning probe
microscopy</a>). These separate data sources are stored as ‘channels’ in
our image.</p>
<figure><img src="../fig/channel-arrays.png" style="width:80.0%" alt="A diagram showing different kinds of channels  for a 4x4 image of a cell e.g. red / green / surface height / elasticity" class="figure mx-auto d-block"></figure><p>This diagram shows an example of a 2D image with channels, but this
can also be extended to 3D images, as we will see now.</p>
<p>Fluorescence microscopy images, like the one we currently have open
in Napari, are common examples of images with multiple channels. In
flourescence microscopy, different ‘flourophores’ are used that target
specific features (like the nucleus or cell membrane) and emit light of
different wavelengths. Images are taken filtering for each of these
wavelengths in turn, giving one image channel per fluorophore. In this
case, there are two channels - one for a flourophore targeting the
nucleus, and one for a fluorophore targeting the cell membrane. These
are shown as separate image layers in Napari’s layer list:</p>
<figure><img src="../fig/layer-list.png" alt="A screenshot of Napari's layer list, showing two  image layers named 'nuclei' and 'membrane'" class="figure mx-auto d-block"></figure><p>Recall from the <a href="imaging-software.html">imaging software
episode</a> that ‘layers’ are how Napari displays multiple items
together in the viewer. Each layer could be an entire image, part of an
image like a single channel, a series of points or shapes etc. Each
layer is displayed as a named item in the layer list, and can have
various display settings adjusted in the layer controls.</p>
<p>Let’s check the shape of both layers:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>nuclei <span class="op">=</span> viewer.layers[<span class="st">"nuclei"</span>].data</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>membrane <span class="op">=</span> viewer.layers[<span class="st">"membrane"</span>].data</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(nuclei.shape)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(membrane.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># (z, y, x)
(60, 256, 256)
(60, 256, 256)</code></pre>
</div>
<p>This shows that each layer contains a 3D image array of size
60x256x256. Each 3D image represents the intensity of light detected at
each (z, y, x) location with a wavelength corresponding to the given
fluorophore.</p>
<p>Here, Napari has automatically recognised that this image contains
different channels and separated them into different image layers. This
is not always the case though, and sometimes it <a href="#when-to-split-channels-into-layers-in-napari">may be preferable
to not split the channels into separate layers</a>! We can merge our
channels again by selecting both image layers (shift + click so they’re
both highlighted in blue), right clicking on them and selecting:<br><code>Merge to stack</code></p>
<p>You should see the two image layers disappear, and a new combined
layer appear in the layer list (labelled ‘membrane’). This image has an
extra slider that allows switching channels - try moving both sliders
and see how the image display changes.</p>
<p>We can check the image’s dimensions with:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"membrane"</span>].data</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># (c, z, y, x)
(2, 60, 256, 256)</code></pre>
</div>
<p>Notice how these dimensions match combining the two layers shown
above. Two arrays with 3 dimensions (60, 256, 256) are combined to give
one array with four dimensions (2, 60, 256, 256) with the first axis
representing the 2 channels. See the diagram below for a visualisation
of how these 3D and 4D arrays compare:</p>
<figure><img src="../fig/3d-4d-arrays.png" style="width:80.0%" alt="A diagram comparing image arrays with three  (z, y, x) and four (c, z, y, x) dimensions" class="figure mx-auto d-block"></figure><p>As we’ve seen before, the labels on the left hand side of each slider
in Napari matches the index of the dimension it moves along. The top
slider (labelled 1) moves along the z axis, while the bottom slider
(labelled 0) switches channels.</p>
<p>We can separate the channels again by right clicking on the
‘membrane’ image layer and selecting:<br><code>Split Stack</code></p>
<p>Note that this resets the contrast limits for membrane and nuclei to
defaults of the min/max possible values. You’ll need to adjust the
contrast limits on the membrane layer to see it clearly again after
splitting.</p>
<div id="reading-channels-in-napari" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="reading-channels-in-napari" class="callout-inner">
<h3 class="callout-title">Reading channels in Napari<a class="anchor" aria-label="anchor" href="#reading-channels-in-napari"></a>
</h3>
<div class="callout-content">
<p>When we open the cells image through the Napari menu, it is really
calling something like:</p>
<pre><code>from skimage import data
viewer.add_image(data.cells3d(), channel_axis=1)</code></pre>
<p>This adds the cells 3D image (which is stored as zcyx), and specifies
that dimension 1 is the channel axis. This allows Napari to split the
channels automatically into different layers.</p>
<p>Usually when loading your own images into Napari e.g. with the
napari-aicsimageio plugin (as we will see in the next episode), the
channel axis should be recognised automatically. If not, you may need to
add the image via the console as above, manually stating the channel
axis.</p>
</div>
</div>
</div>
<div id="when-to-split-channels-into-layers-in-napari" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="when-to-split-channels-into-layers-in-napari" class="callout-inner">
<h3 class="callout-title">When to split channels into layers in
Napari?<a class="anchor" aria-label="anchor" href="#when-to-split-channels-into-layers-in-napari"></a>
</h3>
<div class="callout-content">
<p>As we saw above, we have two choices when loading images with
multiple channels into Napari:</p>
<ul>
<li><p>Load the image as one Napari layer, and use a slider to change
channel</p></li>
<li><p>Load each channel as a separate Napari layer, e.g. using the
<code>channel_axis</code></p></li>
</ul>
<p>Both are useful ways to view multichannel images, and which you
choose will depend on your image and preference. Some pros and cons are
shown below:</p>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>
  Pros and cons
  </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" aria-labelledby="headingSpoiler1" data-bs-parent="#accordionSpoiler1">
<div class="accordion-body">
<p><strong>Channels as separate layers</strong></p>
<ol style="list-style-type: decimal">
<li><p>Channels can be overlaid on top of each other (rather than only
viewed one at a time)</p></li>
<li><p>Channels can be easily shown/hidden with the <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/visibility.svg" alt="A screenshot of Napari's eye button" height="20" class="figure">
icons</p></li>
<li><p>Display settings like contrast limits and colormaps can be
controlled independently for each channel (rather than only for the
entire image)</p></li>
</ol>
<p><strong>Entire image as one layer</strong></p>
<ol style="list-style-type: decimal">
<li><p>Useful when handling a very large number of channels. For
example, if we have hundreds of channels, then moving between them on a
slider may be simpler and faster.</p></li>
<li><p>Napari can become slow, or even crash with a very large number of
layers. Keeping the entire image as one layer can help prevent
this.</p></li>
<li><p>Keeping the full image as one layer can be helpful when running
certain processing operations across multiple channels at once</p></li>
</ol>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section id="time"><h2 class="section-heading">Time<a class="anchor" aria-label="anchor" href="#time"></a>
</h2>
<hr class="half-width">
<p>You should have already downloaded the MitoCheck dataset as part of
the <a href="index.html#setup">setup instructions</a> - if not, you can
download it by clicking on ‘00001_01.ome.tiff’ on <a href="https://docs.openmicroscopy.org/ome-model/5.6.3/ome-tiff/data.html#mitocheck" class="external-link">this
page of the OME website</a>.</p>
<p>To open it in Napari, remove any existing image layers, then drag and
drop the file over the canvas. A popup may appear asking you to choose a
‘reader’ - you can select either ‘napari builtins’ or
‘napari-aicsimageio’. We’ll see in the next episode that the
‘napari-aicsimageio’ reader gives us access to useful image
metadata.</p>
<p>Note this image can take a while to open, so give it some time!
Alternatively, you can select in the top menu-bar:<br><code>File &gt; Open File(s)...</code></p>
<figure><img src="../fig/cells-time-napari.png" alt="A screenshot of a 2D time series in Napari" class="figure mx-auto d-block"></figure><p>This image is a 2D time series (tyx) of some human cells undergoing
mitosis. The slider at the bottom now moves through time, rather than z
or channels. Try moving the slider from left to right - you should see
some nuclei divide and the total number of nuclei increase. You can also
press the small <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/right_arrow.svg" alt="A screenshot of Napari's play button" height="20" class="figure"> icon at
the left side of the slider to automatically move along it. The icon
will change into a <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/square.svg" alt="A screenshot of Napari's stop button" height="25" class="figure">- pressing
this will stop the movement.</p>
<p>We can again check the image dimensions by running the following:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"00001_01.ome"</span>].data</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># (t, y, x)
(93, 1024, 1344)</code></pre>
</div>
<p>Note that this image has a total of 3 dimensions, and so it will also
be stored in a 3D array:</p>
<figure><img src="../fig/tyx-array.png" style="width:40.0%" alt="A diagram of a tyx image array" class="figure mx-auto d-block"></figure><p>This makes the point that the dimensions don’t always represent the
same quantities. For example, a 3D image array with shape (512, 512,
512) could represent a zyx, cyx or tyx image. We’ll discuss this more in
the next section.</p>
</section><section id="dimension-order"><h2 class="section-heading">Dimension order<a class="anchor" aria-label="anchor" href="#dimension-order"></a>
</h2>
<hr class="half-width">
<p>As we’ve seen so far, we can check the number and size of an image’s
dimensions by running:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>image.shape</span></code></pre>
</div>
<p>Napari reads this array and displays the image appropriately, with
the correct number of sliders, based on these dimensions. It’s worth
noting though that Napari doesn’t usually know what these different
dimensions represent e.g.  consider a 4 dimensional image with shape
(512, 512, 512, 512). This could be tcyx, czyx, tzyx etc… Napari will
just display it as an image with 2 additional sliders, not caring about
exactly what each represents.</p>
<p>Python has certain conventions for the order of image axes (like <a href="https://scikit-image.org/docs/stable/user_guide/numpy_images.html#coordinate-conventions" class="external-link">scikit-image’s
‘coordinate conventions’</a> and <a href="https://allencellmodeling.github.io/aicsimageio/aicsimageio.aics_image.AICSImage.html" class="external-link">aicsimageio’s
reader</a>) - but this tends to vary based on the library or plugin
you’re using. These are not firm rules!</p>
<p>Therefore, it’s always worth checking you understand which axes are
being shown in any viewer and what they represent! Check against your
prior knowledge of the experimental setup, and check the metadata in the
original image (we’ll look at this in the next episode). If you want to
change how axes are displayed, remember you can use the roll or
transpose dimensions buttons as discussed in the <a href="imaging-software.html">imaging software episode</a>. Also, if
loading the image manually from the console, you can provide some extra
information like the <code>channel_axis</code> parameter discussed
above.</p>
<div id="interpreting-image-dimensions" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="interpreting-image-dimensions" class="callout-inner">
<h3 class="callout-title">Interpreting image dimensions<a class="anchor" aria-label="anchor" href="#interpreting-image-dimensions"></a>
</h3>
<div class="callout-content">
<p>Remove all image layers, then open a new image by copying and pasting
the following into Napari’s console:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage <span class="im">import</span> data</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.add_image(data.kidney(), rgb<span class="op">=</span><span class="va">False</span>).data</span></code></pre>
</div>
<p>This is a fluorescence microscopy image of mouse kidney tissue.</p>
<ol style="list-style-type: decimal">
<li><p>How many dimensions does it have?</p></li>
<li><p>What do each of those dimensions represent? (e.g. t, c, z, y, x)
<strong>Hint:</strong> try using the roll dimensions button <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/roll.svg" alt="A screenshot of Napari's roll dimensions button" height="25" class="figure">
to view different combinations of axes.</p></li>
<li><p>Once you know which dimension represent channels, remove the
image and load it again with:</p></li>
</ol>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace ? with the correct channel axis</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>viewer.add_image(data.kidney(), rgb<span class="op">=</span><span class="va">False</span>, channel_axis<span class="op">=</span>?)</span></code></pre>
</div>
<p>Note that using the wrong channel axis may cause Napari to crash. If
this happens to you just restart Napari and try again. Bear in mind, as
we saw in the <a href="#when-to-split-channels-into-layers-in-napari">channel splitting
section</a> that large numbers of layers can be difficult to handle, so
it isn’t usually advisable to use ‘channel_axis’ on dimensions with a
large size.</p>
<ol start="4" style="list-style-type: decimal">
<li>How many channels does the image have?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="section level3">
<h3 id="section">1<a class="anchor" aria-label="anchor" href="#section"></a>
</h3>
<p>The image has 4 dimensions, which we can see with:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>image.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(16, 512, 512, 3)</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="section-1">2<a class="anchor" aria-label="anchor" href="#section-1"></a>
</h3>
<p>If we press the roll dimensions button <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/roll.svg" alt="A screenshot of Napari's roll dimensions button" height="25" class="figure">
once, we can see an image of various cells and nuclei. Moving the slider
labelled ‘0’ seems to move up and down in this image (i.e. the z axis),
while moving the slider labelled ‘3’ changes between highlighting
different features like nuclei and cell edges (i.e. channels).
Therefore, the remaining two axes (1 and 2) must be y and x. This means
the image’s 4 dimensions are (z, y, x, c)</p>
</div>
<div class="section level3">
<h3 id="section-2">3<a class="anchor" aria-label="anchor" href="#section-2"></a>
</h3>
<p>The channel axis is 3 (remember that the numbering always starts form
0!)</p>
</div>
<div class="section level3">
<h3 id="section-3">4<a class="anchor" aria-label="anchor" href="#section-3"></a>
</h3>
<p>There are 3 channels which we can see from the <code>.shape</code>
output, or from the number of layers in the layer list.</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="rgb"><h2 class="section-heading">RGB<a class="anchor" aria-label="anchor" href="#rgb"></a>
</h2>
<hr class="half-width">
<p>For the final part of this episode, let’s look at RGB images. RGB
images can be considered as a special case of a 2D image with channels
(yxc). In this case, there are always 3 channels - with one representing
red (R), one representing green (G) and one representing blue (B).</p>
<p>Let’s open an example RGB image with the command below. Make sure you
remove any existing image layers first!<br><code>File &gt; Open Sample &gt; napari builtins &gt; Skin (RGB)</code></p>
<figure><img src="../fig/skin-napari.png" alt="A screenshot of an H+E slide of skin layers  in Napari" class="figure mx-auto d-block"></figure><p>This image is a hematoxylin and eosin stained slide of dermis and
epidermis (skin layers). Let’s check its shape:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> viewer.layers[<span class="st">"skin"</span>].data</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># (y, x, c)
(960, 1280, 3)</code></pre>
</div>
<p>Notice that the channels aren’t separated out into different image
layers, as they were for the multichannel images above. Instead, they
are shown combined together as a single image. If you hover your mouse
over the image, you should see three pixel values printed in the bottom
left representing (R, G, B).</p>
<figure><img src="../fig/rgb-values.png" alt="A screenshot of an H+E slide of skin layers in  Napari, highlighting the (R,G,B) values" class="figure mx-auto d-block"></figure><p>We can see these different channels more clearly if we right click on
the ‘skin’ image layer and select:<br><code>Split RGB</code></p>
<p>This shows the red, green and blue channels as separate image layers.
Try inspecting each one individually by clicking the <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/visibility.svg" alt="A screenshot of Napari's eye button" height="30" class="figure"> icons to
hide the other layers.</p>
<p>We can understand these RGB pixel values better by opening a
different sample image. Remove all layers, then select:<br><code>File &gt; Open Sample &gt; napari builtins &gt; Colorwheel (RGB)</code></p>
<figure><img src="../fig/colorwheel-napari.png" alt="A screenshot of a colorwheel in Napari" class="figure mx-auto d-block"></figure><p>This image shows an RGB colourwheel - try hovering your mouse over
different areas, making note of the (R, G, B) values shown in the bottom
left of Napari. You should see that moving into the red area gives high
values for R, and low values for B and G. Equally, the green area shows
high values for G, and the blue area shows high values for B. The red,
green and blue values are mixed together to give the final colour.</p>
<p>Recall from the <a href="image-display.html">image display
episode</a> that for most microscopy images the colour of each pixel is
determined by a colormap (or LUT). Each pixel usually has a single value
that is then mapped to a corresponding colour via the colormap, and
different colormaps can be used to highlight different features. RGB
images are different - here we have three values (R, G, B) that
unambiguously correspond to a colour for display. For example, (255, 0,
0) would always be fully red, (0, 255, 0) would always be fully green
and so on… This is why there is no option to select a colormap in the
layer controls when an RGB image is displayed. In effect, the colormap
is hard-coded into the image, with a full colour stored for every pixel
location.</p>
<p>These kinds of images are common when we are trying to replicate what
can be seen with the human eye. For example, photos taken with a
standard camera or phone will be RGB. They are less common in
microscopy, although there are certain research fields and types of
microscope that commonly use RGB. A key example is imaging of tissue
sections for histology or pathology. You will also often use RGB images
when preparing figures for papers and presentations - RGB images can be
opened in all imaging software (not just scientific research focused
ones), so are useful when preparing images for display. As usual, always
make sure you keep a copy of your original raw data!</p>
<div id="reading-rgb-in-napari" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="reading-rgb-in-napari" class="callout-inner">
<h3 class="callout-title">Reading RGB in Napari<a class="anchor" aria-label="anchor" href="#reading-rgb-in-napari"></a>
</h3>
<div class="callout-content">
<p>How does Napari know an image is RGB? If an image’s final dimension
has a length of 3 or 4, Napari will assume it is RGB and <a href="https://napari.org/stable/howtos/layers/image.html#viewing-rgb-vs-luminance-grayscale-images" class="external-link">display
it as such</a>. If loading an image from the console, you can also
manually set it to load as rgb:</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage <span class="im">import</span> data</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>viewer.add_image(data.astronaut(), rgb<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="rgb-histograms" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="rgb-histograms" class="callout-inner">
<h3 class="callout-title">RGB histograms<a class="anchor" aria-label="anchor" href="#rgb-histograms"></a>
</h3>
<div class="callout-content">
<p>Make a histogram of the Skin (RGB) image using
<code>napari-matplotlib</code> (as covered in the <a href="image-display.html">image display episode</a>)</p>
<ul>
<li>How does it differ from the image histograms we looked at in the <a href="image-display.html">image display episode</a>?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>If you haven’t completed the <a href="image-display.html">image
display episode</a>, you will need to <a href="image-display.html#napari-plugins">install the
<code>napari-matplotlib</code> plugin</a>.</p>
<p>Then open a histogram with:<br><code>Plugins &gt; napari Matplotlib &gt; Histogram</code></p>
<figure><img src="../fig/rgb-histogram.png" alt="RGB histogram of the Napari Skin sample image" class="figure mx-auto d-block"></figure><p>This histogram shows separate lines for R, G and B - this is because
each displayed pixel is represented by three values (R, G, B). This
differs from the histograms we looked at previously, where there was
only one line as each displayed pixel was only represented by one
value.</p>
</div>
</div>
</div>
</div>
<div id="understanding-rgb-colours" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="understanding-rgb-colours" class="callout-inner">
<h3 class="callout-title">Understanding RGB colours<a class="anchor" aria-label="anchor" href="#understanding-rgb-colours"></a>
</h3>
<div class="callout-content">
<p>What colour would you expect the following (R, G, B) values to
produce? Each value has a minimum of 0 and a maximum of 255.</p>
<ul>
<li>(0, 0, 255)</li>
<li>(255, 255, 255)</li>
<li>(0, 0, 0)</li>
<li>(255, 255, 0)</li>
<li>(100, 100, 100)</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<figure><img src="../fig/rgb-exercise.png" style="width:50.0%" alt="Diagram of (R, G, B) values next to corresponding  colours" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Keypoints<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Microscopy images can have many dimensions, usually representing
time (t), channels (c), and spatial axes (z, y, x)</li>
<li>Napari can open images with any number of dimensions</li>
<li>Napari (and python in general) has no firm rules for axis order.
Different libraries and plugins will often use different
conventions.</li>
<li>RGB images always have 3 channels - red (R), green (G) and blue (B).
These channels aren’t separated into different image layers - they’re
instead combined together to give the final image display.</li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-filetypes-and-metadata"><p>Content from <a href="filetypes-and-metadata.html">Filetypes and metadata</a></p>
<hr>
<p> Last updated on 2024-02-06 | 
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/filetypes-and-metadata.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time <i aria-hidden="true" data-feather="clock"></i> 40 minutes </p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right"> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Which file formats should be used for microscopy images?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain the pros and cons of some popular image file formats</li>
<li>Explain the difference between lossless and lossy compression</li>
<li>Inspect image metadata with the napari-aicsimageio plugin</li>
<li>Inspect and set an image’s scale in Napari</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="image-file-formats"><h2 class="section-heading">Image file formats<a class="anchor" aria-label="anchor" href="#image-file-formats"></a>
</h2>
<hr class="half-width">
<p>Images can be saved in a wide variety of file formats. You may be
familiar with many of these like JPEG (files ending with .jpg or .jpeg
extension), PNG (.png extension) or TIFF (.tiff or .tif extension).
Microscopy images have an especially wide range of options, with
hundreds of different formats in use, often specific to particular
microscope manufacturers. With this being said, how do we choose which
format(s) to use in our research? It’s worth bearing in mind that the
best format to use will vary depending on your research question and
experimental workflow - so you may need to use different formats on
different research projects.</p>
</section><section id="metadata"><h2 class="section-heading">Metadata<a class="anchor" aria-label="anchor" href="#metadata"></a>
</h2>
<hr class="half-width">
<p>First, let’s look closer at what gets stored inside an image
file.</p>
<p>There are two main things that get stored inside image files:
<em>pixel values</em> and <em>metadata</em>. We’ve looked at pixel
values in previous episodes (<a href="what-is-an-image.html">What is an
image?</a>, <a href="image-display.html">Image display</a> and <a href="multi-dimensional-images.html">Multi-dimensional images</a>
episodes) - this is the raw image data as an array of numbers with
specific dimensions and data type. The metadata, on the other hand, is a
wide variety of additional information about the image and how it was
acquired.</p>
<p>For example, let’s take a look at the metadata in the
‘Plate1-Blue-A-12-Scene-3-P3-F2-03.czi’ file we downloaded as part of
the <a href="index.html#setup">setup instructions</a>. To browse the metadata
we will use a Napari plugin called <a href="https://www.napari-hub.org/plugins/napari-aicsimageio" class="external-link">napari-aicsimageio</a>.
This plugin allows a wide variety of file formats to be opened in Napari
that aren’t supported by default. This plugin was already installed in
the <a href="index.html#setup">setup instructions</a>, so you should be able
to start using it straight away.</p>
<p>Let’s open the ‘Plate1-Blue-A-12-Scene-3-P3-F2-03.czi’ file by
removing any existing image layers, then dragging and dropping it onto
the canvas. In the pop-up menu that appears, select
‘napari-aicsimageio’. Note this can take a while to open, so give it
some time! Alternatively, you can select in Napari’s top menu-bar:<br><code>File &gt; Open File(s)...</code></p>
<figure><img src="../fig/plate1-czi-napari.png" alt="A screenshot of yeast sample data shown in  Napari" class="figure mx-auto d-block"></figure><p>This image is part of a <a href="https://idr.openmicroscopy.org/search/?query=Name:idr0011-ledesmafernandez-dad4/screenD" class="external-link">published
dataset on Image Data Resource</a> (accession number idr0011), and comes
from the <a href="https://downloads.openmicroscopy.org/images/Zeiss-CZI/idr0011/" class="external-link">OME
sample data</a>. It is a 3D fluorescence microscopy image of yeast with
three channels (we’ll explore what these channels represent in the <a href="#exploring-metadata">Exploring metadata exercise</a>). Napari has
automatically recognised these three channels and split them into three
separate image layers. Recall that we looked at how Napari handles
channels in the <a href="multi-dimensional-images.html#channels">multi-dimensional images
episode</a>.</p>
<p>We can browse its metadata by selecting in the top menu-bar:<br><code>Plugins &gt; OME Tree Widget (ome-types)</code></p>
<figure><img src="../fig/ome-tree-widget.png" alt="A screenshot of napari-aicsimageio's OME Tree  Widget" class="figure mx-auto d-block"></figure><p>This opens a panel on the right-hand side of Napari listing different
metadata stored in the file. In this case, we can see it is split into
categories like <code>experimenters</code>, <code>images</code> and
<code>instruments</code>… You can click on the different categories to
expand them and see more detail. For example, under
<code>images &gt; Image:0</code>, we see useful metadata about this
specific image. We can see the <code>acquisition_date</code> when this
image was acquired. Also, under <code>pixels</code> we can see
information about the <code>dimension_order</code>, the size of
different dimensions (<code>size_c</code>, <code>size_t</code>,
<code>size_x</code>, <code>size_y</code> and <code>size_z</code>), the
type and bit-depth (<code>type</code>) and importantly the pixel size
(<code>physical_size_x</code>, <code>physical_size_x_unit</code> etc.).
The pixel size is essential for making accurate quantitative
measurements from our images, and will be discussed <a href="#pixel-size">in the next section of this episode</a>.</p>
<p>This metadata is a vital record of exactly how the image was acquired
and what it represents. As we’ve mentioned in previous episodes - it’s
important to maintain this metadata as a record for the future. It’s
also essential to allow us to make quantitative measurements from our
images, by understanding factors like the pixel size. Converting between
file formats can result in loss of metadata, so it’s always worthwhile
keeping a copy of your image safely in its original raw file format. You
should take extra care to ensure that additional processing steps don’t
overwrite this original image.</p>
<div id="exploring-metadata-in-the-console" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="exploring-metadata-in-the-console" class="callout-inner">
<h3 class="callout-title">Exploring metadata in the console<a class="anchor" aria-label="anchor" href="#exploring-metadata-in-the-console"></a>
</h3>
<div class="callout-content">
<p>Note that you can also inspect some metadata via the console (as
below). Here we use python’s <a href="https://github.com/Textualize/rich" class="external-link">rich</a> library to add
colour-coding to make the output easier to read:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rich</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>rich.<span class="bu">print</span>(viewer.layers[<span class="dv">0</span>].metadata)</span></code></pre>
</div>
<figure><img src="../fig/metadata-console.png" alt="Screenshot of metadata printed to Napari's  console" class="figure mx-auto d-block"></figure><p>See the <a href="https://github.com/AllenCellModeling/napari-aicsimageio?tab=readme-ov-file#access-to-the-aicsimage-object-and-metadata" class="external-link">napari-aicsimageio
readme</a> for details.</p>
</div>
</div>
</div>
<div id="exploring-metadata" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exploring-metadata" class="callout-inner">
<h3 class="callout-title">Exploring metadata<a class="anchor" aria-label="anchor" href="#exploring-metadata"></a>
</h3>
<div class="callout-content">
<p>Explore the metadata in the OME Tree Widget panel to answer the
following questions:</p>
<ul>
<li>What manufacturer made the microscope used to take this image?</li>
<li>What detector was used to take this image?</li>
<li>What does each channel show? For example, which fluorophore is used?
What is its excitation and emission wavelength?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="section level3">
<h3 id="microscope-model">Microscope model<a class="anchor" aria-label="anchor" href="#microscope-model"></a>
</h3>
<p>Under <code>instruments &gt; Instrument:0 &gt; microscope</code>, we
can see that the manufacturer was Zeiss.</p>
</div>
<div class="section level3">
<h3 id="detector">Detector<a class="anchor" aria-label="anchor" href="#detector"></a>
</h3>
<p>Under
<code>instruments &gt; Instrument:0 &gt; detectors &gt; Detector:HDCam</code>,
we can see that this used an HDCamC10600-30B (ORCA-R2) detector.</p>
</div>
<div class="section level3">
<h3 id="channels">Channels<a class="anchor" aria-label="anchor" href="#channels"></a>
</h3>
<p>Under <code>images &gt; Image:0 &gt; pixels &gt; channels</code>, we
can see one entry per channel - <code>Channel:1-0</code>,
<code>Channel:2-0</code> and <code>Channel:3-0</code>.</p>
<p>Expanding the first, we can see that its <code>fluor</code> is
TagYFP, a fluorophore with <code>emission_wavelength</code> of 524nm and
<code>excitation_wavelength</code> of 508nm.</p>
<p>Expanding the second, we can see that its <code>fluor</code> is
mRFP1.2, a fluorophore with <code>emission_wavelength</code> of 612nm
and <code>excitation_wavelength</code> of 590nm.</p>
<p>Expanding the third, we see that it has no <code>fluor</code>,
<code>emission_wavelength</code> or <code>excitation_wavelength</code>
listed. Its <code>illumination_type</code> is listed as ‘transmitted’,
so this is simply an image of the yeast cells with no fluorophores
used.</p>
</div>
</div>
</div>
</div>
</div>
<div id="napari-aicsimagio-image-metadata-support" class="callout callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="napari-aicsimagio-image-metadata-support" class="callout-inner">
<h3 class="callout-title">Napari-aicsimagio image / metadata
support<a class="anchor" aria-label="anchor" href="#napari-aicsimagio-image-metadata-support"></a>
</h3>
<div class="callout-content">
<p>Only certain file types will support browsing metadata via the ‘OME
Tree Widget’ in napari-aicsimageio. The plugin is still under
development - so more formats are likely to be supported in future!</p>
<p>Napari-aicsimageio also has <a href="https://github.com/AllenCellModeling/napari-aicsimageio?tab=readme-ov-file#reading-mode-threshold" class="external-link">limits
on the size of images</a> it will load directly into memory. Only images
with a filesize less than 4GB and less than 30% of available memory will
be loaded directly. Otherwise, images are loaded as smaller chunks as
required.</p>
<p>If you have difficulty opening a specific file format with
napari-aicsimageio, it’s worth trying to open it in <a href="https://imagej.net/software/fiji/" class="external-link">Fiji</a> also. Fiji has very
well established integration with Bio-Formats, and so tends to support a
wider range of formats. Note that you can always save your image (or
part of your image) as another format like .tiff via Fiji to open in
Napari later (making sure you still retain a copy of the original file
and its metadata!)</p>
</div>
</div>
</div>
</section><section id="pixel-size"><h2 class="section-heading">Pixel size<a class="anchor" aria-label="anchor" href="#pixel-size"></a>
</h2>
<hr class="half-width">
<p>One of the most important pieces of metadata is the pixel size. In
our .czi image, this is stored under
<code>images &gt; Image:0 &gt; pixels</code> as
<code>physical_size</code> and <code>physical_size_unit</code> for each
axis (x, y and z). The pixel size states how large a pixel is in
physical units i.e. ‘real world’ units of measurement like micrometre,
or millimetre. In this case the unit given is ‘μm’ (micrometre). This
means that each pixel has a size of 0.20μm (x axis), 0.20μm (y axis) and
0.35μm (z axis). As this image is 3D, you will sometimes hear the pixels
referred to as ‘voxels’, which is just a term for a 3D pixel.</p>
<p>The pixel size is important to ensure that any measurements made on
the image are correct. For example, how long is a particular cell? Or
how wide is each nucleus? These answers can only be correct if the pixel
size is properly set. It’s also useful when we want to overlay different
images on top of each other (potentially acquired with different kinds
of microscope) - setting the pixel size appropriately will ensure their
overall size matches correctly in the Napari viewer.</p>
<p>How do we set the pixel size in Napari? Most of the time, if the
pixel size is provided in the image metadata, napari-aicsimageio will
set it automatically in a property called <code>scale</code>. We can
check this by running the following in Napari’s console:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first image layer</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>image_layer <span class="op">=</span> viewer.layers[<span class="dv">0</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print its scale</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image_layer.scale)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code># [z y x]
[0.35 0.2047619 0.2047619]</code></pre>
</div>
<p>Each image layer in Napari has a <code>.scale</code> which is
equivalent to the pixel size. Here we can see that it is already set to
values matching the image metadata.</p>
<p>If the pixel size isn’t listed in the metadata, or napari-aicsimagio
doesn’t read it correctly, you can set it manually like so:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>image_layer.scale <span class="op">=</span> (<span class="fl">0.35</span>, <span class="fl">0.2047619</span>, <span class="fl">0.2047619</span>)</span></code></pre>
</div>
<div id="pixel-size-scale" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="pixel-size-scale" class="callout-inner">
<h3 class="callout-title">Pixel size / scale<a class="anchor" aria-label="anchor" href="#pixel-size-scale"></a>
</h3>
<div class="callout-content">
<p>Copy and paste the following into Napari’s console to get
<code>image_layer_1</code>, <code>image_layer_2</code> and
<code>image_layer_3</code> of the yeast image:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>image_layer_1 <span class="op">=</span> viewer.layers[<span class="dv">0</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>image_layer_2 <span class="op">=</span> viewer.layers[<span class="dv">1</span>]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>image_layer_3 <span class="op">=</span> viewer.layers[<span class="dv">2</span>]</span></code></pre>
</div>
<ol style="list-style-type: decimal">
<li>Check the <code>.scale</code> of each layer - are they the
same?</li>
<li>Set the scale of layer 3 to (0.35, 0.4, 0.4) - what changes in the
viewer?</li>
<li>Set the scale of layer 3 to (0.35, 0.4, 0.2047619) - what changes in
the viewer?</li>
<li>Set the scale of all layers so they are half as wide and half as
tall as their original size in the viewer</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="section level3">
<h3 id="section">1<a class="anchor" aria-label="anchor" href="#section"></a>
</h3>
<p>All layers have the same scale</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image_layer_1.scale)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image_layer_2.scale)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image_layer_3.scale)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[0.35 0.2047619 0.2047619]
[0.35 0.2047619 0.2047619]
[0.35 0.2047619 0.2047619]</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="section-1">2<a class="anchor" aria-label="anchor" href="#section-1"></a>
</h3>
<figure><img src="../fig/yeast-exercise-2.png" alt="Yeast image shown in Napari with layer 3  twice as big in y and x" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>image_layer_3.scale <span class="op">=</span> (<span class="fl">0.35</span>, <span class="fl">0.4</span>, <span class="fl">0.4</span>)</span></code></pre>
</div>
<p>You should see that layer 3 becomes about twice as wide and twice as
tall as the other layers. This is because we set the pixel size in y and
x (which used to be 0.2047619μm) to about twice its original value (now
0.4μm).</p>
</div>
<div class="section level3">
<h3 id="section-2">3<a class="anchor" aria-label="anchor" href="#section-2"></a>
</h3>
<figure><img src="../fig/yeast-exercise-3.png" alt="Yeast image shown in Napari with layer 3  twice as big in y" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>image_layer_3.scale <span class="op">=</span> (<span class="fl">0.35</span>, <span class="fl">0.4</span>, <span class="fl">0.2047619</span>)</span></code></pre>
</div>
<p>You should see that layer 3 appears squashed - with the same width as
other layers, but about twice the height. This is because we set the
pixel size in y (which used to be 0.2047619μm) to about twice its
original value (now 0.4μm). Bear in mind that setting the pixel sizes
inappropriately can lead to stretched or squashed images like this!</p>
</div>
<div class="section level3">
<h3 id="section-3">4<a class="anchor" aria-label="anchor" href="#section-3"></a>
</h3>
<figure><img src="../fig/yeast-exercise-4.png" alt="Yeast image shown in Napari with all layers  half size in y/x" class="figure mx-auto d-block"></figure><p>We set the pixel size in y/x to half its original value of
0.2047619μm:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>image_layer_1.scale <span class="op">=</span> (<span class="fl">0.35</span>, <span class="fl">0.10238095</span>, <span class="fl">0.10238095</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>image_layer_2.scale <span class="op">=</span> (<span class="fl">0.35</span>, <span class="fl">0.10238095</span>, <span class="fl">0.10238095</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>image_layer_3.scale <span class="op">=</span> (<span class="fl">0.35</span>, <span class="fl">0.10238095</span>, <span class="fl">0.10238095</span>)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section id="choosing-a-file-format"><h2 class="section-heading">Choosing a file format<a class="anchor" aria-label="anchor" href="#choosing-a-file-format"></a>
</h2>
<hr class="half-width">
<p>Now that we’ve seen an example of browsing metadata in Napari, let’s
look more closely into how we can decide on a file format. There are
many factors to consider, including:</p>
<div class="section level3">
<h3 id="dimension-support">Dimension support<a class="anchor" aria-label="anchor" href="#dimension-support"></a>
</h3>
<p>Some file formats will only support certain dimensions e.g. 2D, 3D, a
specific number of channels… For example, .png and .jpg only support 2D
images (either grayscale or RGB), while .tiff can support images with
many more dimensions (including any number of channels, time, 2D and 3D
etc.).</p>
</div>
<div class="section level3">
<h3 id="metadata-support">Metadata support<a class="anchor" aria-label="anchor" href="#metadata-support"></a>
</h3>
<p>As mentioned above, image metadata is a very important record of how
an image was acquired and what it represents. Different file formats
have different standards for how to store metadata, and what kind of
metadata they accept. This means that converting between file formats
often results in loss of some metadata.</p>
</div>
<div class="section level3">
<h3 id="compatibility-with-software">Compatibility with software<a class="anchor" aria-label="anchor" href="#compatibility-with-software"></a>
</h3>
<p>Some image analysis software will only support certain image file
formats. If a format isn’t supported, you will likely need to make a
copy of your data in a new format.</p>
</div>
<div class="section level3">
<h3 id="proprietary-vs-open-formats">Proprietary vs open formats<a class="anchor" aria-label="anchor" href="#proprietary-vs-open-formats"></a>
</h3>
<p>Many light microscopes will save data automatically into their own
proprietary file formats (owned by the microscope company). For example,
Zeiss microscopes often save files to a format with a .czi extension,
while Leica microscopes often use a format with a .lif extension. These
formats will retain all the metadata used during acquisition, but are
often difficult to open in software that wasn’t created by the same
company.</p>
<p><a href="https://www.openmicroscopy.org/bio-formats/" class="external-link">Bio-Formats</a>
is an open-source project that helps to solve this problem - allowing
over 100 file formats to be opened in many pieces of open source
software. Napari-aicsimageio (that we used earlier in this episode)
integrates with Bio-Formats to allow many different file formats to be
opened in Napari. Bio-Formats is really essential to allow us to work
with these multitude of formats! Even so, it won’t support absolutely
everything, so you will likely need to convert your data to another file
format sometimes. If so, it’s good practice to use an open file format
whose specification is freely available, and can be opened in many
different pieces of software e.g. OME-TIFF.</p>
</div>
<div class="section level3">
<h3 id="compression">Compression<a class="anchor" aria-label="anchor" href="#compression"></a>
</h3>
<p>Different file formats use different types of ‘compression’.
Compression is a way to reduce image file sizes, by changing the way
that the image pixel values are stored. There are many different
compression algorithms that compress files in different ways.</p>
<p>Many compression algorithms rely on finding areas of an image with
similar pixel values that can be stored in a more efficient way. For
example, imagine a row of 30 pixels from an 8-bit grayscale image:</p>
<figure><img src="../fig/image-line.png" alt="Diagram of a line of 30 pixels - 10 with pixel  value 50, then 10 with pixel value 100, then 10 with pixel value 150" class="figure mx-auto d-block"></figure><p>Normally, this would be stored as 30 individual pixel values, but we
can reduce this greatly by recognising that many of the pixel values are
the same. We could store the exact same data with only 6 values: 10 50
10 100 10 150, showing that there are 10 values with pixel value 50,
then 10 with value 100, then 10 with value 150. This is the general idea
behind ‘run-length encoding’ and many compression algorithms use similar
principles to reduce file sizes.</p>
<p>There are two main types of compression:</p>
<ul>
<li><p><strong>Lossless compression</strong> algorithms are reversible -
when the file is opened again, it can be reversed perfectly to give the
exact same pixel values.</p></li>
<li><p><strong>Lossy compression</strong> algorithms reduce the size by
irreversibly altering the data. When the file is opened again, the pixel
values will be different to their original values. Some image quality
may be lost via this process, but it can achieve much smaller file
sizes.</p></li>
</ul>
<p>For microscopy data, you should therefore use a file format with no
compression, or lossless compression. Lossy compression should be
avoided as it degrades the pixel values and may alter the results of any
analysis that you perform!</p>
<div id="compression-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="compression-1" class="callout-inner">
<h3 class="callout-title">Compression<a class="anchor" aria-label="anchor" href="#compression-1"></a>
</h3>
<div class="callout-content">
<p>Let’s remove all layers from the Napari viewer, and open the
‘00001_01.ome.tiff’ dataset. You should have already downloaded this to
your working directory as part of the <a href="index.html#setup">setup
instructions</a>.</p>
<p>Run the code below in Napari’s console. This will save a specific
timepoint of this image (time = 30) as four different file formats
(.tiff, .png + low and high quality .jpg). Note: these files will be
written to the same folder as the ‘00001_01.ome.tiff’ image!</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage.io <span class="im">import</span> imsave</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the 00001_01.ome layer, and get timepoint = 30</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>layer <span class="op">=</span> viewer.layers[<span class="st">"00001_01.ome"</span>]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> layer.data[<span class="dv">30</span>, :, :]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Save as different file formats in same folder as 00001_01.ome</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>folder_path <span class="op">=</span> Path(layer.source.path).parent</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>imsave( folder_path <span class="op">/</span> <span class="st">"test-tiff.tiff"</span>, image)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>imsave( folder_path <span class="op">/</span> <span class="st">"test-png.png"</span>, image)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>imsave( folder_path <span class="op">/</span> <span class="st">"test-jpg-high-quality.jpg"</span>, image, quality<span class="op">=</span><span class="dv">75</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>imsave( folder_path <span class="op">/</span> <span class="st">"test-jpg-low-quality.jpg"</span>, image, quality<span class="op">=</span><span class="dv">30</span>)</span></code></pre>
</div>
<ul>
<li><p>Go to the folder where ‘00001_01.ome.tiff’ was saved and look at
the file sizes of the newly written images (<code>test-tiff</code>,
<code>test-png</code>, <code>test-jpg-high-quality</code> and
<code>test-jpg-low-quality</code>). Which is biggest? Which is
smallest?</p></li>
<li><p>Open all four images in Napari. Zoom in very close to a bright
nucleus, and try showing / hiding different layers with the <img src="https://raw.githubusercontent.com/napari/napari/main/napari/resources/icons/visibility.svg" alt="A screenshot of Napari's eye button" height="30" class="figure"> icon. How
do they differ? How does each compare to timepoint 30 of the original
‘00001_01.ome’ image?</p></li>
<li><p>Which file formats use lossy compression?</p></li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<div class="section level3">
<h3 id="file-sizes">File sizes<a class="anchor" aria-label="anchor" href="#file-sizes"></a>
</h3>
<p>‘test_tiff’ is largest, followed by ‘test-png’, then
‘test-jpg-high-quality’, then ‘test-jpg-low-quality’.</p>
</div>
<div class="section level3">
<h3 id="differences-to-original">Differences to original<a class="anchor" aria-label="anchor" href="#differences-to-original"></a>
</h3>
<p>By showing/hiding different layers, you should see that ‘test-tiff’
and ‘test-png’ look identical to the original image (when its slider is
set to timepoint 30). In contrast, both jpg files show blocky artefacts
around the nuclei - the pixel values have clearly been altered. This
effect is worse in the low quality jpeg than the high quality one.</p>
</div>
<div class="section level3">
<h3 id="lossy-compression">Lossy compression<a class="anchor" aria-label="anchor" href="#lossy-compression"></a>
</h3>
<p>Both jpg files use lossy compression, as they alter the original
pixel values. The low quality jpeg compresses the file more than the
high quality jpeg, resulting in smaller file sizes, but also worse
alteration of the pixel values. The rest of the file formats (.tiff /
.png) use no compression, or lossless compression - so their pixel
values are identical to the original values.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="handling-of-large-image-data">Handling of large image data<a class="anchor" aria-label="anchor" href="#handling-of-large-image-data"></a>
</h3>
<p>If your images are very large, you may need to use a pyramidal file
format that is specialised for handling them. Pyramidal file formats
store images at multiple resolutions (and usually in small chunks) so
that they can be browsed smoothly without having to load all of the
full-resolution data. This is similar to how google maps allows browsing
of its vast quantities of map data. Specialised software like <a href="https://qupath.github.io/" class="external-link">QuPath</a>, <a href="https://imagej.net/plugins/bdv/" class="external-link">Fiji’s BigDataViewer</a> and <a href="https://www.openmicroscopy.org/omero/" class="external-link">OMERO’s viewer</a> can
provide smooth browsing of these kinds of images.</p>
<p>See below for an example image pyramid (using napari’s Cells (3D +
2Ch) sample image) with three different resolution levels stored. Each
level is about twice as small the last in x and y:</p>
<figure><img src="../fig/image-pyramid.png" style="width:40.0%" alt="Diagram of an image pyramid with three  resolution levels" class="figure mx-auto d-block"></figure>
</div>
</section><section id="common-file-formats"><h2 class="section-heading">Common file formats<a class="anchor" aria-label="anchor" href="#common-file-formats"></a>
</h2>
<hr class="half-width">
<p>As we’ve seen so far, there are many different factors to consider
when choosing file formats. As different file formats have various pros
and cons, it is very likely that you will use different formats for
different purposes. For example, having one file format for your raw
acquisition data, another for some intermediate analysis steps, and
another for making diagrams and figures for display. Pete Bankhead’s
bioimage book has a great chapter on <a href="https://bioimagebook.github.io/chapters/1-concepts/6-files/files.html" class="external-link">Files
&amp; file formats</a> that explores this in detail.</p>
<p>To finish this episode, let’s look at some common file formats you
are likely to encounter (this table is from <a href="https://bioimagebook.github.io/chapters/1-concepts/6-files/files.html#table-file-formats" class="external-link">Pete
Bankhead’s bioimage book</a> which is released under a CC-BY 4.0
license):</p>
<table class="table">
<colgroup>
<col width="14%">
<col width="17%">
<col width="17%">
<col width="17%">
<col width="34%">
</colgroup>
<thead><tr class="header">
<th align="left">Format</th>
<th align="left">Extensions</th>
<th align="left">Main use</th>
<th align="left">Compression</th>
<th align="left">Comment</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">TIFF</td>
<td align="left">.tif, .tiff</td>
<td align="left">Analysis, display (print)</td>
<td align="left">None, lossless, lossy</td>
<td align="left">Very general image format</td>
</tr>
<tr class="even">
<td align="left">OME-TIFF</td>
<td align="left">.ome.tif, .ome.tiff</td>
<td align="left">Analysis, display (print)</td>
<td align="left">None, lossless, lossy</td>
<td align="left">TIFF, with standardized metadata for microscopy</td>
</tr>
<tr class="odd">
<td align="left">Zarr</td>
<td align="left">.zarr</td>
<td align="left">Analysis</td>
<td align="left">None, lossless, lossy</td>
<td align="left">Emerging format, great for big datasets – but limited
support currently</td>
</tr>
<tr class="even">
<td align="left">PNG</td>
<td align="left">.png</td>
<td align="left">Display (web, print)</td>
<td align="left">Lossless</td>
<td align="left">Small(ish) file sizes without compression
artefacts</td>
</tr>
<tr class="odd">
<td align="left">JPEG</td>
<td align="left">.jpg, .jpeg</td>
<td align="left">Display (web)</td>
<td align="left">Lossy (usually)</td>
<td align="left">Small file sizes, but visible artefacts</td>
</tr>
</tbody>
</table>
<p>Note that there are many, many proprietary microscopy file formats in
addition to these! You can get a sense of how many by browsing
Bio-Formats list of <a href="https://bio-formats.readthedocs.io/en/v7.1.0/supported-formats.html" class="external-link">supported
formats</a>.</p>
<p>You’ll also notice that many file formats support different types of
compression e.g. none, lossless or lossy (as well as different
compression settings like the ‘quality’ we saw on jpeg images earlier).
You’ll have to make sure you are using the right kind of compression
when you save images into these formats.</p>
<p>To summarise some general recommendations:</p>
<ul>
<li><p>During acquisition, it’s usually a good idea to use whatever the
standard proprietary format is for that microscope. This will ensure you
retain as much metadata as possible, and have maximum compatibility with
that company’s acquisition and analysis software.</p></li>
<li><p>During analysis, sometimes you can directly use the format you
acquired your raw data in. If it’s not supported, or you need to save
new images of e.g.  sub-regions of an image, then it’s a good idea to
switch to one of the formats in the table above specialised for analysis
(TIFF and OME-TIFF are popular choices).</p></li>
<li><p>Finally, for display, you will need to use common file formats
that can be opened in any imaging software (not just scientific) like
png, jpeg or tiff. Note that jpeg usually uses lossy compression, so
it’s only advisable if you need very small file sizes (for example, for
displaying many images on a website).</p></li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Keypoints<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Image files contain pixel values and metadata.</li>
<li>Metadata is an important record of how an image was acquired and
what it represents.</li>
<li>Napari-aicsimagio allows many more image file formats to be opened
in Napari, along with providing easy browsing of some metadata.</li>
<li>Pixel size states how large a pixel is in physical units
(e.g. micrometre).</li>
<li>Compression can be lossless or lossy - lossless is best for
microscopy images.</li>
<li>There are many, many different microscopy file formats. The best
format to use depends on your use-case e.g. acquisition, analysis or
display.</li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-designing-a-light-microscopy-experiment"><p>Content from <a href="designing-a-light-microscopy-experiment.html">Designing a light microscopy experiment</a></p>
<hr>
<p> Last updated on 2024-02-07 | 
        
        <a href="https://example.com/FIXME-template-source/edit/main/episodes/designing-a-light-microscopy-experiment.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time <i aria-hidden="true" data-feather="clock"></i> 40 minutes </p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right"> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the key factors to consider when designing a light
microscopy experiment?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li><p>Explain the main steps of designing a light microscopy
experiment</p></li>
<li><p>Describe a few examples of common microscopy methods
e.g. widefield, confocal</p></li>
<li><p>Explain factors to consider when choosing a microscopy
technique</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In previous episodes we focused on the fundamentals of how images are
stored and displayed, with Napari as our main example. In the next few
episodes, we will instead focus on how to design an experiment using
light microscopy and how to analyse the resulting image data.</p>
<section id="steps-to-designing-a-light-microscopy-experiment"><h2 class="section-heading">Steps to designing a light microscopy experiment<a class="anchor" aria-label="anchor" href="#steps-to-designing-a-light-microscopy-experiment"></a>
</h2>
<hr class="half-width">
<p>As we’ve said throughout the course, there is no one ‘right’ way of
analysing image data. It depends on the specific images and research
question, with different solutions being best for different situations.
The same holds true for designing a light microscopy experiment - here
we’ll discuss some general guidelines, but the specifics will depend on
your particular research project.</p>
<p>For the sake of this episode, let’s imagine a scenario where we are
investigating the effects of a specific chemical on cells grown in
culture. What steps would we take to design a light microscopy
experiment for this?</p>
<p>A general workflow could be:</p>
<ol style="list-style-type: decimal">
<li><p>Define your research question</p></li>
<li><p>Define what you need to observe to answer that question</p></li>
<li><p>Define what you need to measure to answer that question</p></li>
<li><p>Choose a light microscopy method that fits your data
needs</p></li>
<li><p>Choose acquisition settings that fit your data needs</p></li>
</ol></section><section id="define-your-research-question"><h2 class="section-heading">Define your research question<a class="anchor" aria-label="anchor" href="#define-your-research-question"></a>
</h2>
<hr class="half-width">
<p>Clearly defining your research question is the essential starting
point. What do you want to find out from your microscopy experiment?</p>
<p>For our chemical example, the main aim could be: Does the chemical
affect the number, size or shape of cell nuclei over time?</p>
<p>Then we could form more specific research questions e.g.</p>
<ul>
<li><p>Does the addition of the chemical result in an increase in the
number of cell nuclei over ten hours?</p></li>
<li><p>Does the addition of the chemical result in an increase in the
average nucleus diameter over ten hours?</p></li>
<li><p>Does the addition of the chemical result in an increase in the
roundness of cell nuclei over ten hours?</p></li>
</ul>
<p>For the rest of the episode, we will stick to our very broad research
aim of: ‘Does the chemical affect the number, size or shape of cell
nuclei over time?’. This will allow us to have a broad discussion of
many different approaches to designing a light microscopy experiment.
Bear in mind that in a real experiment you should be as specific as
possible with your research question!</p>
</section><section id="define-what-you-need-to-observe"><h2 class="section-heading">Define what you need to observe<a class="anchor" aria-label="anchor" href="#define-what-you-need-to-observe"></a>
</h2>
<hr class="half-width">
<p>The next step is to figure out what you need to observe to answer
your research question. For example:</p>
<ul>
<li><p>What structures/events do you need to see?</p></li>
<li><p>Do you need fluorescent labels? If so, how many?</p></li>
<li><p>Over what spatial scale? E.g. large tissue sections vs small 3D
volumes</p></li>
<li><p>Over what timescale? E.g. do you need live cell imaging to follow
events over time, or is a snapshot of fixed cells enough?</p></li>
<li><p>2D or 3D?</p></li>
</ul>
<div id="what-do-you-need-to-observe" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="what-do-you-need-to-observe" class="callout-inner">
<h3 class="callout-title">What do you need to observe?<a class="anchor" aria-label="anchor" href="#what-do-you-need-to-observe"></a>
</h3>
<div class="callout-content">
<p>What would you need to observe to answer our research question? -
‘Does the chemical affect the number, size or shape of cell nuclei over
time?’</p>
<p>Think about the points above and make a list of potential answers. It
may be best to discuss in a group, so you can share different ideas.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="section level3">
<h3 id="structures-events">Structures / events<a class="anchor" aria-label="anchor" href="#structures-events"></a>
</h3>
<p>We need to see individual nuclei, with enough resolution to see their
size and overall shape.</p>
</div>
<div class="section level3">
<h3 id="fluorescent-labels">Fluorescent labels<a class="anchor" aria-label="anchor" href="#fluorescent-labels"></a>
</h3>
<p>We will probably need a fluorescent label for the nuclei. This will
allow them to be easily identified in our images so the number, size and
shape can be measured.</p>
<p>Note that it is possible to see and measure nuclei from un-labelled
cells also (e.g. from phase contrast or DIC images, as we will cover in
the <a href="#widefield">widefield section of this episode</a>). The
downside is that it’s much harder to automatically recognise and measure
nuclei from these kinds of images. Unlike images of fluorescently
labelled nuclei, there is a much less clear separation between nuclei
and the rest of the cell, making analysis more challenging.</p>
</div>
<div class="section level3">
<h3 id="spatial-scale">Spatial scale<a class="anchor" aria-label="anchor" href="#spatial-scale"></a>
</h3>
<p>We need to observe many nuclei at once, to get a good estimate of
their number and average shape and size. Therefore, our spatial scale
should encompass an area large enough to image many nuclei for each
timepoint (say 100 nuclei).</p>
</div>
<div class="section level3">
<h3 id="timescale">Timescale<a class="anchor" aria-label="anchor" href="#timescale"></a>
</h3>
<p>As we are interested in how the nuclei number, shape and size changes
over time, we will need to use live cell imaging. We will need to image
for long enough to see multiple cell divisions, so we can assess how the
number of nuclei increases. The length of time required will depend on
the cell line you are using, as they each take a different length of
time to divide.</p>
</div>
<div class="section level3">
<h3 id="d-or-3d">2D or 3D<a class="anchor" aria-label="anchor" href="#d-or-3d"></a>
</h3>
<p>This will depend on how we want to measure nucleus size and shape (as
we’ll look at in the next section of this episode). For example, if we
want to accurately characterise the volume and 3D shape of the nuclei
then we will need to image in 3D. If we’re instead happy to estimate
from 2D measures like nucleus diameter, then 2D is sufficient. This
again highlights the need for a specific research question! In a real
life experiment, we should probably define more clearly exactly what
aspects of nucleus size and shape we are interested in, as this will
help to inform the need for 2D or 3D.</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="define-what-you-need-to-measure"><h2 class="section-heading">Define what you need to measure<a class="anchor" aria-label="anchor" href="#define-what-you-need-to-measure"></a>
</h2>
<hr class="half-width">
<p>Once we have a good idea of what we need to observe, we need to
clearly define what measurements are required.</p>
<ul>
<li><p>What do you need to quantify from your images to answer your
question? E.g. cell length, nucleus volume, the number of cells with a
specific fluorescent label…</p></li>
<li><p>How will you quantify them? E.g. which image processing software?
What kind of analysis methods?</p></li>
<li><p>How many objects/events do you need to quantify?</p></li>
</ul>
<p>As the second point indicates, it’s always worthwhile to consider how
you will quantify your images before you collect them. This will make
the image analysis steps much faster and ensure that you are collecting
images optimised for the given method. We’ll look at image processing
methods more in later episodes.</p>
<p>For the last point, it’s important to consider any statistical tests
you will use to answer your research question, and the sample size
required to give them sufficient statistical ‘power’. Statistical power
is the likelihood of a statistical test detecting an effect when one is
actually present. For example, consider testing if there is a difference
of X% in the number of cells when grown with and without our chemical of
interest. If there really is a difference, a statistical power of 0.8
(80%) would mean that out of 100 different studies, 80 of them would
detect it. Having a high statistical power is vital to ensure that our
experiment has a good chance of detecting the effects we are interested
in. There is a clear relationship between sample size and power, with
larger sample sizes resulting in higher power to detect the same effect.
Conducting a ‘power analysis’ is a good way to assess a reasonable
minimum sample size for your experiment. A full discussion of this is
outside of the scope of this course, but there are links to further
resources in the <a href="FIXME.html">final episode</a>.</p>
<div id="what-do-you-need-to-measure" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="what-do-you-need-to-measure" class="callout-inner">
<h3 class="callout-title">What do you need to measure?<a class="anchor" aria-label="anchor" href="#what-do-you-need-to-measure"></a>
</h3>
<div class="callout-content">
<p>Consider the two points below and make a list of potential answers
for our research question ‘Does the chemical affect the number, size or
shape of cell nuclei over time?’:</p>
<ul>
<li>What do you need to quantify from your images to answer your
question?</li>
<li>How will you quantify them?</li>
</ul>
<p>It may be best to discuss in a group, so you can share different
ideas.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="section level3">
<h3 id="what-to-quantify">What to quantify?<a class="anchor" aria-label="anchor" href="#what-to-quantify"></a>
</h3>
<p>For nucleus number, we will need to count the number of nuclei
present at each timepoint.</p>
<p>For nucleus size, there are many different options. If we’re imaging
in 2D, we could measure the nucleus area, or the width at its widest
point. For 3D, we could measure nucleus volume, or again the width at
its widest point…</p>
<p>For nucleus shape, there are even more options. In 2D we could, for
example, measure the nucleus ‘roundness’ (a measure of how circular it
is). In 3D, we could measure nucleus ‘sphericity’ (a measure of how
spherical it is). Which measures you use will often depend on which
image analysis software you use. Many analysis packages have a wide
range of shape (morphological) features built-in e.g. Napari has a
plugin called ‘napari-skimage-regionprops’ that offers <a href="https://www.napari-hub.org/plugins/napari-skimage-regionprops#features" class="external-link">many
different features</a>.</p>
</div>
<div class="section level3">
<h3 id="how-to-quantify">How to quantify?<a class="anchor" aria-label="anchor" href="#how-to-quantify"></a>
</h3>
<p>Here again there is no one correct answer - a lot will depend on
which image analysis software you use and your personal preference. For
example, let’s say you decided on imaging in 3D and measuring nucleus
number, volume and sphericity with Napari. Before we can make any
measurements from the cells, we first need to ‘segment’ the nuclei
i.e. identify which pixels in the image correspond to each nucleus
(we’ll look at this in detail in later episodes). For some tasks, this
could be as simple as drawing a contour or boundary around the cell.
However, as we are looking to quantify many nuclei at many different
timepoints, it’s not feasible to do this manually - we’ll need to
develop an automated workflow to segment the nuclei and measure their
volume and sphericity. We’ll look at some techniques for this kind of
analysis in the <a href="FIXME.html">manual segmentation</a>, <a href="FIXME.html">thresholding</a> and <a href="FIXME.html">instance
segmentation</a> episodes.</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="choose-a-light-microscopy-method"><h2 class="section-heading">Choose a light microscopy method<a class="anchor" aria-label="anchor" href="#choose-a-light-microscopy-method"></a>
</h2>
<hr class="half-width">
<p>For the final part of this episode, let’s look at how we can choose a
light microscopy method for our experiment. We’ll look at the last step
(choosing acquisition settings) in the next episode.</p>
<p>Often the first step in choosing a light microscopy technique is
discussing with other members of your research group or department. What
are most of them using, for what kind of experiments? If you are working
with a microscopy core facility, then the people who work there are also
a great source of advice and recommendations. Finally, you can also
explore the literature for research questions and experiments similar to
yours to see which methods are used most often.</p>
<p>There’s a very wide variety of light microscopes available (from many
different manufacturers) that are specialised for different kinds of
samples. We’ll take a brief look at some popular options below, but
there are far too many to cover in a single episode. Bear this in mind
when choosing light microscopy techniques for your own experiments -
there are many more options to consider!</p>
<div class="section level3">
<h3 id="widefield">Widefield<a class="anchor" aria-label="anchor" href="#widefield"></a>
</h3>
<p>In a widefield microscope, the entire sample is illuminated by the
light source at once. The light source can illuminate the sample from
below (in an upright microscope) or from above (in an inverted
microscope).</p>
<p>In it’s simplest form, a widefield microscope can be used for
‘brightfield microscopy’. This is simply where the sample is illuminated
by a bright light from one side, and then imaged from the other. The
issue with this method is that it often produces low-contrast images,
where it’s difficult to see biological structures. This is because
biological structures are often quite transparent - they don’t absorb
much light or differ much in their density. For this reason, contrast
agents/staining are often used to increase contrast (i.e.  the addition
of dyes/chemicals that bind to specific structures).</p>
<figure><img src="../fig/skin.png" style="width:70.0%" alt="Screenshot of Napari's Skin sample image" class="figure mx-auto d-block"><figcaption>The image above is Napari’s Skin (RGB) sample image -
it is a brightfield image of a hematoxylin and eosin stained slide of
dermis and epidermis.</figcaption></figure><p>To increase contrast (especially for unstained samples), widefield
microscopes often support <a href="https://www.microscopyu.com/techniques/phase-contrast/introduction-to-phase-contrast-microscopy" class="external-link">‘phase-contrast’</a>
or <a href="https://www.leica-microsystems.com/science-lab/microscopy-basics/differential-interference-contrast-dic/" class="external-link">‘DIC
- Differential Interference Contrast’</a>. Both these methods make use
of slight changes in the ‘phase’ of light as it passes through a sample
to increase contrast.</p>
<figure><img src="../fig/phase-contrast.jpg" style="width:70.0%" alt="Phase gradient contrast image of SH-SY5Y  cells" class="figure mx-auto d-block"><figcaption>The image above is a phase gradient contrast image of
some SH-SY5Y cells (ZEISS Microscopy, <a href="https://creativecommons.org/licenses/by/2.0" class="external-link">CC BY 2.0</a>, via <a href="https://commons.wikimedia.org/wiki/File:SH-SY5Y_cells,_transmitted_light_phase_gradient_contrast_microscopy_with_ZEISS_Celldiscoverer_7_(30614936722).jpg" class="external-link">Wikimedia
Commons</a> )</figcaption></figure><figure><img src="../fig/dic-example.jpg" style="width:50.0%" alt="DIC image of some yeast cells - Saccharomyces  cerevisiae" class="figure mx-auto d-block"><figcaption>The image above is a DIC image of some yeast cells
(<em>Saccharomyces cerevisiae</em>) from <a href="https://commons.wikimedia.org/wiki/File:S_cerevisiae_under_DIC_microscopy.jpg" class="external-link">Wikimedia
Commons</a></figcaption></figure><p>Widefield microscopes can also be used for fluorescence microscopy.
In fluorescence microscopy, fluorescent labels are used that target
specific features (like the nucleus or cell membrane). These labels are
excited by a specific wavelength of light (the excitation wavelength),
and then emit light of a longer wavelength (the emission wavelength). By
illuminating the sample with light of the excitation wavelength, then
detecting light of the emission wavelength, a fluorescence microscope
can image the biological structures that the label is bound to.</p>
<p>It’s worth noting that optimising a fluorescence microscopy setup can
be quite complex! For example, depending on the structure you want to
image, it can be difficult to acquire labels that bind specifically and
don’t interfere with normal function and localisation. This requires
multiple initial tests to verify where a label binds, as well as the
appropriate conditions to use (like incubation time / temperature). In
addition, if you want to image multiple fluorescent labels at the same
time, then you have to ensure there is minimal overlap between their
excitation/emission wavelengths. Labels must also be chosen to match the
available lasers/filters on your microscope of choice - otherwise you
will be unable to properly excite and collect emitted light from them.
These considerations are true for all types of fluorescence microscope -
including widefield and also confocal (that will be discussed
below).</p>
<figure><img src="../fig/fluorescence-example.jpg" style="width:70.0%" alt="Fluorescence microscopy image of some  LLC-PK1 cells" class="figure mx-auto d-block"><figcaption>The image above is a fluorescence microscopy image of
some LLC-PK1 cells (ZEISS Microscopy, <a href="https://creativecommons.org/licenses/by/2.0" class="external-link">CC BY 2.0</a>, via <a href="https://commons.wikimedia.org/wiki/File:Mitotic_LLC-PK1_cells,_fluorescence_microscopy_(23700644352).jpg" class="external-link">Wikimedia
Commons</a> )</figcaption></figure><p>The main issue with widefield microscopes is that, due to the whole
sample being illuminated, it can produce rather blurry images
(especially for thicker samples). For example, in widefield fluorescence
microscopy, fluorophores throughout the entire sample will be emitting
light. This means that the resulting image will represent light from the
focal plane, and also from out-of-focus planes above and below it. This
can result in details being obscured by out-of-focus light.</p>
</div>
<div class="section level3">
<h3 id="confocal">Confocal<a class="anchor" aria-label="anchor" href="#confocal"></a>
</h3>
<p>Confocal microscopes are capable of ‘optical sectioning’ meaning they
can detect light only from the plane of focus and exclude light from
out-of-focus planes. This is extremely useful, especially for thick
samples, to achieve clear images where details aren’t obscured by
out-of-focus light.</p>
<p>There are many different types of confocal microscopes, but one of
the most common is laser scanning confocal microscopes. These are also
known as point scanning confocal microscopes. In this microscope, a
laser is focused onto a single point of the specimen at a time (rather
than illuminating the entire sample). The point of illumination is then
moved across the sample in a raster pattern (i.e. line by line), with
light detected point by point. This gradually builds up the final
image.</p>
<p>Confocal microscopes are typically used for fluorescence microscopy,
especially when it is necessary to image the shape of structures in full
3D. However, this form of imaging also comes with some disadvantages.
For example, confocal microscopes will generally be more complex to use
and slower to acquire images than a widefield microscope. Although there
are other types of confocal that are faster than laser scanning systems,
such as ‘spinning disc confocal microscopes’. Spinning disc systems
split the laser into hundreds of focused beams using an array of
carefully arranged pinholes on a round disc. Spinning the disc causes
the beams to rapidly scan across the sample and acquire an image, much
faster than using a single beam as a standard laser-scanning confocal
does. For more information, <a href="https://www.nature.com/articles/s41596-020-0313-9" class="external-link">Jonkman et
al.’s review</a> gives a great summary of different confocal methods -
e.g. see figure 2 for a comparison of laser-scanning and spinning disc
confocals.</p>
<figure><img src="../fig/confocal-example.png" style="width:60.0%" alt="Screenshot  of Napari's Kidney (3D + 3Ch) sample image" class="figure mx-auto d-block"><figcaption>The image above is Napari’s Kidney (3D + 3Ch) sample
image. This was acquired with confocal fluorescence microscopy.</figcaption></figure>
</div>
<div class="section level3">
<h3 id="super-resolution">Super-resolution<a class="anchor" aria-label="anchor" href="#super-resolution"></a>
</h3>
<p>Before the invention of ‘super-resolution’ methods, it was thought
that light microscopes had a maximum resolution of around 200nm due to
the <a href="https://www.microscopyu.com/techniques/super-resolution/the-diffraction-barrier-in-optical-microscopy" class="external-link">‘diffraction
limit’</a> of light. Super-resolution methods allow microscopes to
surpass this limit, achieving resolutions down to tens of nanometres.
This allows many biological structures, previously only visible with
techniques like electron microscopy, to be viewed with light
microscopes. Many of these super-resolution systems are based on
modified widefield or confocal microscope setups. The increase in
resolution they provide usually comes at the cost of increased
complexity in experiment/microscope setup. There are far too many types
of super-resolution to cover in this episode, but <a href="https://www.nature.com/articles/s41556-018-0251-8_" class="external-link">Schermelleh et
al.</a> and <a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0110" class="external-link">Prakash
et al</a> provide useful reviews if you are interested.</p>
</div>
<div class="section level3">
<h3 id="choosing-a-method">Choosing a method<a class="anchor" aria-label="anchor" href="#choosing-a-method"></a>
</h3>
<p>Choosing a light microscopy method is about finding the simplest and
fastest approach that can address your research question. For example,
does it provide the resolution you need? Can it provide good images of
thick vs thin samples? Does it image a large enough area? Does it image
fast enough to provide the temporal resolution you need?… The online <a href="https://www.bioimagingguide.org/welcome.html" class="external-link">bioimaging guide</a>
provides a <a href="https://www.bioimagingguide.org/02_Sample_acquisition/Picking.html" class="external-link">useful
flowchart</a> to give you some ideas - as well as links to many other
great microscopy resources. We’ve also placed a small summary table
below of the microscopy techniques we covered in this episode.</p>
<p>If your research question can be solved by a simpler and less costly
method, then usually this is the way to go! It’s all about choosing the
right tool for the job - different approaches will be best for different
research questions. For example, you could count cell number with a
high-end super-resolution microscope, but this is also possible with a
standard widefield which will be simpler and faster. In general, only
move to more complex techniques when your research question really
requires it. This also holds true for later steps like choosing image
processing and statistical analysis methods.</p>
<table class="table">
<colgroup>
<col width="27%">
<col width="36%">
<col width="36%">
</colgroup>
<thead><tr class="header">
<th align="left">Technique</th>
<th align="left">What is it?</th>
<th align="left">Key points</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Brightfield</td>
<td align="left">Illuminates the sample with light from one side, and
images on the other</td>
<td align="left">Hard to see many biological structures - usually
requires contrast agents/staining to increase contrast</td>
</tr>
<tr class="even">
<td align="left">Phase contrast / DIC</td>
<td align="left">Makes use of slight changes in the ‘phase’ of light as
it passes through a sample to increase contrast</td>
<td align="left">Allows unstained samples to be seen more easily</td>
</tr>
<tr class="odd">
<td align="left">Widefield flourescence</td>
<td align="left">Fluorescent labels (with specific excitation and
emission wavelengths) bind to specific biological structures</td>
<td align="left">Widefield illuminates the whole sample at once, which
can lead to blurry images in thicker samples</td>
</tr>
<tr class="even">
<td align="left">Laser scanning confocal</td>
<td align="left">A laser is scanned across the sample point by point in
a raster pattern</td>
<td align="left">Allows ‘optical sectioning’, giving clearer images in
full 3D. More complex to use than widefield, also slower to acquire
images.</td>
</tr>
<tr class="odd">
<td align="left">Spinning disc confocal</td>
<td align="left">An array of pinholes on a disc split the laser into
hundreds of beams that move across the sample</td>
<td align="left">Faster than standard laser scanning confocal</td>
</tr>
<tr class="even">
<td align="left">Super-resolution</td>
<td align="left">Wide range of methods that break the classic
‘diffraction limit’ of light, allowing resolutions down to tens of
nanometres</td>
<td align="left">More complex to use than standard widefield /
confocal</td>
</tr>
</tbody>
</table>
<div id="which-microscope" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="which-microscope" class="callout-inner">
<h3 class="callout-title">Which microscope?<a class="anchor" aria-label="anchor" href="#which-microscope"></a>
</h3>
<div class="callout-content">
<p>Which light microscopes could be used to answer our research question
- ‘Does the chemical affect the number, size or shape of cell nuclei
over time?’</p>
<p>Think about the points above and make a list of potential answers. It
may be best to discuss in a group, so you can share different ideas.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">
  Show me the solution
  </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Again, there’s no one solution here - it depends on which elements of
nucleus shape and size we’re focusing on. If we’re happy with 2D
measures, then widefield fluorescence microscopy would be a great option
to allow large numbers of nuclei to be imaged over time.</p>
<p>If we’re more interested in the precise 3D volume and shape, then
confocal fluorescence microscopy would be a better fit. We’d have to be
careful with how often we wanted to image the cells vs the speed of
acquisition though.</p>
<p>As we are using live cell imaging, we have to carefully consider how
often we need to take an image to answer our research question. For
example, if we want to track the rapid movement and divisions of
individual nuclei, then we will need to image quickly, with a small time
interval between each image. Alternatively, if we only need to measure
overall changes in mean nucleus number/size/shape (without exactly
tracking every nucleus) then we can allow much longer time intervals
between each image. For rapid imaging, it may be necessary to use a
microscope specialised for high speed (such as a spinning disc
confocal), otherwise slower methods (such as a standard laser scanning
confocal) can also work very well.</p>
<p>Super-resolution options wouldn’t be required here. Cell nuclei can
be easily visualised with standard widefield and confocal approaches, as
they have a large diameter of around 5-20 micrometre (depending on cell
type). This is well above the classic ‘diffraction limit’ of around
200nm that we discussed in the <a href="#super-resolution">super-resolution section</a>. There’s no need
to introduce any extra complexity, as our research question doesn’t
require that level of resolution.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Keypoints<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>
<p>A general workflow for designing a light microscopy experiment
should include:</p>
<ul>
<li>Define your research question</li>
<li>Define what you need to observe to answer that question</li>
<li>Define what you need to measure to answer that question</li>
<li>Choose a light microscopy method that fits your data needs</li>
<li>Choose acquisition settings that fit your data needs</li>
</ul>
</li>
<li><p>There are many different types of light microscope - including
widefield and confocal</p></li>
<li><p>You should choose the simplest methods (in acquisition,
processing, and statistical analysis) that allow you to address your
research question</p></li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
				<p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://example.com/FIXME-template-source/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://example.com/FIXME-template-source/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a> 
        | <a href="https://example.com/FIXME-template-source/" class="external-link">Source</a></p>
				<p><a href="https://example.com/FIXME-template-source/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="../LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p><a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">Template licensed under CC-BY 4.0</a> by <a href="https://carpentries.org" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/HealthBioscienceIDEAS/sandpaper/tree/IDEAS" class="external-link">sandpaper (0.14.1.9000)</a>,
        <a href="https://github.com/carpentries/pegboard/tree/1bc5753e917d515c3d888ce6cc013c0a680eacfc" class="external-link">pegboard (0.7.3)</a>,
      and <a href="https://github.com/HealthBioscienceIDEAS/varnish/tree/IDEAS" class="external-link">varnish (0.3.3.9000)</a>.</p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
			<i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back to top"></i><br><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://FIXME-template-source.github.io/NA/instructor/aio.html",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://FIXME-template-source.github.io/NA/instructor/aio.html",
  "identifier": "https://FIXME-template-source.github.io/NA/instructor/aio.html",
  "dateCreated": "2023-10-26",
  "dateModified": "2024-02-13",
  "datePublished": "2024-02-13"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

